{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Revenue Prediction\n",
    "\n",
    "The 80/20 rule has proven true for many businesses–only a small percentage of customers produce most of the revenue. As such, marketing teams are challenged to make appropriate investments in promotional strategies.\n",
    "This notebook will analyze a Google Merchandise Store (also known as GStore, where Google swag is sold) customer dataset from Kaggle competition ['Google Analytics Customer Revenue Prediction'](https://www.kaggle.com/c/ga-customer-revenue-prediction) to predict revenue per customer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the dataset:\n",
    "\n",
    "Each row in the dataset is one visit to the store. Targeted outputs are prediction of the natural log of the sum of all transactions per user.\n",
    "\n",
    "The data fields in the given files are\n",
    "\n",
    "* fullVisitorId- A unique identifier for each user of the Google Merchandise Store.\n",
    "* channelGrouping - The channel via which the user came to the Store.\n",
    "* date - The date on which the user visited the Store.\n",
    "* device - The specifications for the device used to access the Store.\n",
    "* geoNetwork - This section contains information about the geography of the user.\n",
    "* sessionId - A unique identifier for this visit to the store.\n",
    "* socialEngagementType - Engagement type, either \"Socially Engaged\" or \"Not Socially Engaged\".\n",
    "* totals - This section contains aggregate values across the session.\n",
    "* trafficSource - This section contains information about the Traffic Source from which the session originated.\n",
    "* visitId - An identifier for this session. This is part of the value usually stored as the _utmb cookie. This is only unique to the user. For a completely unique ID, you should use a combination of fullVisitorId and visitId.\n",
    "* visitNumber - The session number for this user. If this is the first session, then this is set to 1.\n",
    "* visitStartTime - The timestamp (expressed as POSIX time).\n",
    "\n",
    "Note: some of the fields are in json format, the dataset size is very large. The train and test datasets used in this analysis is a cvs file with json flattened from Kaggle [json flattened csv data](https://www.kaggle.com/colinpearse/ga-analytics-with-json-columns)(thanks to Collin!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc   # garbage collector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets and Extract Train_Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some repeated datetime and starttime process\n",
    "train = pd.read_csv('./Output/train_p.csv')\n",
    "train.drop(['Unnamed: 0'],axis=1, inplace=True)\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "train['visitStartTime'] = train['visitStartTime']. apply(lambda x: datetime.datetime.fromtimestamp(x).strftime('%-H'))\n",
    "\n",
    "test = pd.read_csv('./Output/test_p.csv')\n",
    "test.drop(['Unnamed: 0'],axis=1, inplace=True)\n",
    "test['date'] = pd.to_datetime(test['date'])\n",
    "test['visitStartTime'] = test['visitStartTime']. apply(lambda x: datetime.datetime.fromtimestamp(x).strftime('%-H'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelGrouping</th>\n",
       "      <th>date</th>\n",
       "      <th>fullVisitorId</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>visitId</th>\n",
       "      <th>visitNumber</th>\n",
       "      <th>visitStartTime</th>\n",
       "      <th>device.browser</th>\n",
       "      <th>device.deviceCategory</th>\n",
       "      <th>device.isMobile</th>\n",
       "      <th>...</th>\n",
       "      <th>geoNetwork.networkDomain</th>\n",
       "      <th>geoNetwork.subContinent</th>\n",
       "      <th>totals.hits</th>\n",
       "      <th>totals.newVisits</th>\n",
       "      <th>totals.pageviews</th>\n",
       "      <th>totals.transactionRevenue</th>\n",
       "      <th>trafficSource.medium</th>\n",
       "      <th>trafficSource.source</th>\n",
       "      <th>weekday</th>\n",
       "      <th>mon_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>2016-09-02</td>\n",
       "      <td>1131660440785968503</td>\n",
       "      <td>1131660440785968503_1472830385</td>\n",
       "      <td>1472830385</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>desktop</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>ttnet.com.tr</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>google</td>\n",
       "      <td>4</td>\n",
       "      <td>0902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>2016-09-02</td>\n",
       "      <td>377306020877927890</td>\n",
       "      <td>377306020877927890_1472880147</td>\n",
       "      <td>1472880147</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>desktop</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>dodo.net.au</td>\n",
       "      <td>Australasia</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>google</td>\n",
       "      <td>4</td>\n",
       "      <td>0902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>2016-09-02</td>\n",
       "      <td>3895546263509774583</td>\n",
       "      <td>3895546263509774583_1472865386</td>\n",
       "      <td>1472865386</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>desktop</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>unknown.unknown</td>\n",
       "      <td>Southern Europe</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>google</td>\n",
       "      <td>4</td>\n",
       "      <td>0902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>2016-09-02</td>\n",
       "      <td>4763447161404445595</td>\n",
       "      <td>4763447161404445595_1472881213</td>\n",
       "      <td>1472881213</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>UC Browser</td>\n",
       "      <td>desktop</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>unknown.unknown</td>\n",
       "      <td>Southeast Asia</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>google</td>\n",
       "      <td>4</td>\n",
       "      <td>0902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>2016-09-02</td>\n",
       "      <td>27294437909732085</td>\n",
       "      <td>27294437909732085_1472822600</td>\n",
       "      <td>1472822600</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>mobile</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>unknown.unknown</td>\n",
       "      <td>Northern Europe</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>google</td>\n",
       "      <td>4</td>\n",
       "      <td>0902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  channelGrouping       date        fullVisitorId  \\\n",
       "0  Organic Search 2016-09-02  1131660440785968503   \n",
       "1  Organic Search 2016-09-02   377306020877927890   \n",
       "2  Organic Search 2016-09-02  3895546263509774583   \n",
       "3  Organic Search 2016-09-02  4763447161404445595   \n",
       "4  Organic Search 2016-09-02    27294437909732085   \n",
       "\n",
       "                        sessionId     visitId  visitNumber visitStartTime  \\\n",
       "0  1131660440785968503_1472830385  1472830385            1              8   \n",
       "1   377306020877927890_1472880147  1472880147            1             22   \n",
       "2  3895546263509774583_1472865386  1472865386            1             18   \n",
       "3  4763447161404445595_1472881213  1472881213            1             22   \n",
       "4    27294437909732085_1472822600  1472822600            2              6   \n",
       "\n",
       "  device.browser device.deviceCategory  device.isMobile   ...    \\\n",
       "0         Chrome               desktop            False   ...     \n",
       "1        Firefox               desktop            False   ...     \n",
       "2         Chrome               desktop            False   ...     \n",
       "3     UC Browser               desktop            False   ...     \n",
       "4         Chrome                mobile             True   ...     \n",
       "\n",
       "  geoNetwork.networkDomain geoNetwork.subContinent totals.hits  \\\n",
       "0             ttnet.com.tr            Western Asia           1   \n",
       "1              dodo.net.au             Australasia           1   \n",
       "2          unknown.unknown         Southern Europe           1   \n",
       "3          unknown.unknown          Southeast Asia           1   \n",
       "4          unknown.unknown         Northern Europe           1   \n",
       "\n",
       "  totals.newVisits totals.pageviews  totals.transactionRevenue  \\\n",
       "0              1.0              1.0                        0.0   \n",
       "1              1.0              1.0                        0.0   \n",
       "2              1.0              1.0                        0.0   \n",
       "3              1.0              1.0                        0.0   \n",
       "4              NaN              1.0                        0.0   \n",
       "\n",
       "   trafficSource.medium  trafficSource.source  weekday mon_day  \n",
       "0               organic                google        4    0902  \n",
       "1               organic                google        4    0902  \n",
       "2               organic                google        4    0902  \n",
       "3               organic                google        4    0902  \n",
       "4               organic                google        4    0902  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data visualization showed weekdays have more user activities than weekend; \n",
    "#there are more activities during special occasions like Velentine's day. These can be important features to include for the model training\n",
    "train['weekday']=train['date'].apply(lambda x: x.weekday())\n",
    "test['weekday']=test['date'].apply(lambda x: x.weekday())\n",
    "\n",
    "train['mon_day'] = train['date'].apply(lambda x: str(f\"{x:%m}\")+str(f\"{x:%d}\"))\n",
    "test['mon_day'] = test['date'].apply(lambda x:  str(f\"{x:%m}\")+str(f\"{x:%d}\"))\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 903653 entries, 0 to 903652\n",
      "Data columns (total 23 columns):\n",
      "channelGrouping              903653 non-null object\n",
      "date                         903653 non-null datetime64[ns]\n",
      "fullVisitorId                903653 non-null object\n",
      "sessionId                    903653 non-null object\n",
      "visitId                      903653 non-null int64\n",
      "visitNumber                  903653 non-null int64\n",
      "visitStartTime               903653 non-null object\n",
      "device.browser               903645 non-null object\n",
      "device.deviceCategory        903653 non-null object\n",
      "device.isMobile              903653 non-null bool\n",
      "device.operatingSystem       898958 non-null object\n",
      "geoNetwork.continent         902185 non-null object\n",
      "geoNetwork.country           902185 non-null object\n",
      "geoNetwork.networkDomain     658772 non-null object\n",
      "geoNetwork.subContinent      902185 non-null object\n",
      "totals.hits                  903653 non-null int64\n",
      "totals.newVisits             703060 non-null float64\n",
      "totals.pageviews             903553 non-null float64\n",
      "totals.transactionRevenue    903653 non-null float64\n",
      "trafficSource.medium         903533 non-null object\n",
      "trafficSource.source         903584 non-null object\n",
      "weekday                      903653 non-null int64\n",
      "mon_day                      903653 non-null object\n",
      "dtypes: bool(1), datetime64[ns](1), float64(3), int64(4), object(14)\n",
      "memory usage: 152.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['channelGrouping', 'date', 'fullVisitorId', 'sessionId', 'visitId',\n",
      "       'visitNumber', 'visitStartTime', 'device.browser',\n",
      "       'device.deviceCategory', 'device.isMobile', 'device.operatingSystem',\n",
      "       'geoNetwork.continent', 'geoNetwork.country',\n",
      "       'geoNetwork.networkDomain', 'geoNetwork.subContinent', 'totals.hits',\n",
      "       'totals.newVisits', 'totals.pageviews', 'totals.transactionRevenue',\n",
      "       'trafficSource.medium', 'trafficSource.source', 'weekday', 'mon_day'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 features will be used to train model, including: \n",
      "['channelGrouping', 'visitNumber', 'visitStartTime', 'device.browser', 'device.deviceCategory', 'device.isMobile', 'device.operatingSystem', 'geoNetwork.continent', 'geoNetwork.country', 'geoNetwork.networkDomain', 'geoNetwork.subContinent', 'totals.hits', 'totals.newVisits', 'totals.pageviews', 'trafficSource.medium', 'trafficSource.source', 'weekday', 'mon_day']\n"
     ]
    }
   ],
   "source": [
    "pop_cols = ['date', 'fullVisitorId', 'sessionId', 'visitId','totals.transactionRevenue']\n",
    "feature_cols = [col for col in train.columns if col not in pop_cols]\n",
    "print('{} features will be used to train model, including: \\n{}'.format(len(feature_cols), feature_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{dtype('bool'): Index(['device.isMobile'], dtype='object'), dtype('int64'): Index(['visitNumber', 'totals.hits', 'weekday'], dtype='object'), dtype('float64'): Index(['totals.newVisits', 'totals.pageviews'], dtype='object'), dtype('O'): Index(['channelGrouping', 'visitStartTime', 'device.browser',\n",
      "       'device.deviceCategory', 'device.operatingSystem',\n",
      "       'geoNetwork.continent', 'geoNetwork.country',\n",
      "       'geoNetwork.networkDomain', 'geoNetwork.subContinent',\n",
      "       'trafficSource.medium', 'trafficSource.source', 'mon_day'],\n",
      "      dtype='object')}\n"
     ]
    }
   ],
   "source": [
    "df=train[feature_cols]\n",
    "col_type = df.columns.to_series().groupby(df.dtypes).groups\n",
    "print(col_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert categorical features to int type before constructing Dataset for LGB model\n",
    "cat_cols = ['device.isMobile', 'channelGrouping', 'visitStartTime', 'device.browser',\n",
    "       'device.deviceCategory', 'device.operatingSystem',\n",
    "       'geoNetwork.continent', 'geoNetwork.country',\n",
    "       'geoNetwork.networkDomain', 'geoNetwork.subContinent',\n",
    "       'trafficSource.medium', 'trafficSource.source', 'mon_day']\n",
    "\n",
    "for col in cat_cols:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(train[col].tolist()+test[col].tolist())\n",
    "    train[col]=le.transform(train[col].tolist())\n",
    "    test[col]=le.transform(test[col].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelGrouping</th>\n",
       "      <th>date</th>\n",
       "      <th>fullVisitorId</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>visitId</th>\n",
       "      <th>visitNumber</th>\n",
       "      <th>visitStartTime</th>\n",
       "      <th>device.browser</th>\n",
       "      <th>device.deviceCategory</th>\n",
       "      <th>device.isMobile</th>\n",
       "      <th>...</th>\n",
       "      <th>geoNetwork.networkDomain</th>\n",
       "      <th>geoNetwork.subContinent</th>\n",
       "      <th>totals.hits</th>\n",
       "      <th>totals.newVisits</th>\n",
       "      <th>totals.pageviews</th>\n",
       "      <th>totals.transactionRevenue</th>\n",
       "      <th>trafficSource.medium</th>\n",
       "      <th>trafficSource.source</th>\n",
       "      <th>weekday</th>\n",
       "      <th>mon_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-09-02</td>\n",
       "      <td>1131660440785968503</td>\n",
       "      <td>1131660440785968503_1472830385</td>\n",
       "      <td>1472830385</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>37454</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>207</td>\n",
       "      <td>4</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-09-02</td>\n",
       "      <td>377306020877927890</td>\n",
       "      <td>377306020877927890_1472880147</td>\n",
       "      <td>1472880147</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10097</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>207</td>\n",
       "      <td>4</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-09-02</td>\n",
       "      <td>3895546263509774583</td>\n",
       "      <td>3895546263509774583_1472865386</td>\n",
       "      <td>1472865386</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>38725</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>207</td>\n",
       "      <td>4</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-09-02</td>\n",
       "      <td>4763447161404445595</td>\n",
       "      <td>4763447161404445595_1472881213</td>\n",
       "      <td>1472881213</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>38725</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>207</td>\n",
       "      <td>4</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-09-02</td>\n",
       "      <td>27294437909732085</td>\n",
       "      <td>27294437909732085_1472822600</td>\n",
       "      <td>1472822600</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>38725</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>207</td>\n",
       "      <td>4</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   channelGrouping       date        fullVisitorId  \\\n",
       "0                4 2016-09-02  1131660440785968503   \n",
       "1                4 2016-09-02   377306020877927890   \n",
       "2                4 2016-09-02  3895546263509774583   \n",
       "3                4 2016-09-02  4763447161404445595   \n",
       "4                4 2016-09-02    27294437909732085   \n",
       "\n",
       "                        sessionId     visitId  visitNumber  visitStartTime  \\\n",
       "0  1131660440785968503_1472830385  1472830385            1              22   \n",
       "1   377306020877927890_1472880147  1472880147            1              15   \n",
       "2  3895546263509774583_1472865386  1472865386            1              10   \n",
       "3  4763447161404445595_1472881213  1472881213            1              15   \n",
       "4    27294437909732085_1472822600  1472822600            2              20   \n",
       "\n",
       "   device.browser  device.deviceCategory  device.isMobile   ...     \\\n",
       "0              34                      0                0   ...      \n",
       "1              42                      0                0   ...      \n",
       "2              34                      0                0   ...      \n",
       "3              78                      0                0   ...      \n",
       "4              34                      1                1   ...      \n",
       "\n",
       "   geoNetwork.networkDomain  geoNetwork.subContinent  totals.hits  \\\n",
       "0                     37454                       20            1   \n",
       "1                     10097                        0            1   \n",
       "2                     38725                       18            1   \n",
       "3                     38725                       15            1   \n",
       "4                     38725                       12            1   \n",
       "\n",
       "   totals.newVisits  totals.pageviews  totals.transactionRevenue  \\\n",
       "0               1.0               1.0                        0.0   \n",
       "1               1.0               1.0                        0.0   \n",
       "2               1.0               1.0                        0.0   \n",
       "3               1.0               1.0                        0.0   \n",
       "4               NaN               1.0                        0.0   \n",
       "\n",
       "   trafficSource.medium  trafficSource.source  weekday  mon_day  \n",
       "0                     5                   207        4      244  \n",
       "1                     5                   207        4      244  \n",
       "2                     5                   207        4      244  \n",
       "3                     5                   207        4      244  \n",
       "4                     5                   207        4      244  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[feature_cols]\n",
    "X_test = test[feature_cols]\n",
    "y_train = train['totals.transactionRevenue'].apply(lambda x: np.log(x) if x> 0 else 0)\n",
    "\n",
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light Gradient Boosting Baseline Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.62404\n",
      "Early stopping, best iteration is:\n",
      "[215]\tvalid_0's rmse: 1.62283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.62283"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def modelfit(X_train1, y_train1, X_val, y_val):\n",
    "    train_data = lgb.Dataset(X_train1, label=y_train1)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "    params = {\n",
    "    \"objective\" : \"regression\",\n",
    "    \"metric\" : \"rmse\", \n",
    "    \"num_leaves\" : 31,\n",
    "    \"max_depth\" : 5,\n",
    "    \"min_data_in_leaf\": 20,\n",
    "    \"learning_rate\" : 0.1,\n",
    "    \"bagging_fraction\" : 1,\n",
    "    \"feature_fraction\" : 1\n",
    "    }\n",
    "\n",
    "    bst = lgb.train(params, train_data, 1000, valid_sets=[val_data], early_stopping_rounds=300, verbose_eval=300)\n",
    "\n",
    "    pred_val = bst.predict(X_val, num_iteration=bst.best_iteration)\n",
    "    val_rmse=round(np.sqrt(metrics.mean_squared_error(y_val, pred_val)),5)\n",
    "    return(val_rmse)\n",
    "modelfit(X_train1, y_train1, X_val, y_val)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameter Optimization 1 - learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.6633\n",
      "[600]\tvalid_0's rmse: 1.6413\n",
      "[900]\tvalid_0's rmse: 1.63102\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 1.62931\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.632\n",
      "[600]\tvalid_0's rmse: 1.62341\n",
      "[900]\tvalid_0's rmse: 1.62339\n",
      "Early stopping, best iteration is:\n",
      "[665]\tvalid_0's rmse: 1.62248\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.62452\n",
      "[600]\tvalid_0's rmse: 1.62171\n",
      "[900]\tvalid_0's rmse: 1.62248\n",
      "Early stopping, best iteration is:\n",
      "[629]\tvalid_0's rmse: 1.62169\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.62217\n",
      "[600]\tvalid_0's rmse: 1.62367\n",
      "Early stopping, best iteration is:\n",
      "[327]\tvalid_0's rmse: 1.62157\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.62404\n",
      "Early stopping, best iteration is:\n",
      "[215]\tvalid_0's rmse: 1.62283\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.62711\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's rmse: 1.62426\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.63029\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's rmse: 1.62415\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_data_in_leaf</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>bagging_fraction</th>\n",
       "      <th>feature_fraction</th>\n",
       "      <th>val_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_leaves  max_depth  min_data_in_leaf  learning_rate  bagging_fraction  \\\n",
       "0        31.0        5.0              20.0           0.01               1.0   \n",
       "1        31.0        5.0              20.0           0.03               1.0   \n",
       "2        31.0        5.0              20.0           0.05               1.0   \n",
       "3        31.0        5.0              20.0           0.07               1.0   \n",
       "4        31.0        5.0              20.0           0.10               1.0   \n",
       "5        31.0        5.0              20.0           0.15               1.0   \n",
       "6        31.0        5.0              20.0           0.20               1.0   \n",
       "\n",
       "   feature_fraction  val_rmse  \n",
       "0               1.0   1.62931  \n",
       "1               1.0   1.62248  \n",
       "2               1.0   1.62169  \n",
       "3               1.0   1.62157  \n",
       "4               1.0   1.62283  \n",
       "5               1.0   1.62426  \n",
       "6               1.0   1.62415  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def modelfit_param(X_train1, y_train1, X_val, y_val,nl,md,mdil,lr,bf,ff):\n",
    "    train_data = lgb.Dataset(X_train1, label=y_train1)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "    params = {\n",
    "    \"objective\" : \"regression\",\n",
    "    \"metric\" : \"rmse\", \n",
    "    \"num_leaves\" : nl,\n",
    "    \"max_depth\" : md,\n",
    "    \"min_data_in_leaf\": mdil,\n",
    "    \"learning_rate\" : lr,\n",
    "    \"bagging_fraction\" : bf,\n",
    "    \"feature_fraction\" : ff\n",
    "    }\n",
    "\n",
    "    bst = lgb.train(params, train_data, 1000, valid_sets=[val_data], early_stopping_rounds=300, verbose_eval=300)\n",
    "\n",
    "    pred_val = bst.predict(X_val, num_iteration=bst.best_iteration)\n",
    "    val_rmse=round(np.sqrt(metrics.mean_squared_error(y_val, pred_val)),5)\n",
    "    return(val_rmse)\n",
    "\n",
    "LR_score = dict()\n",
    "for lr in [0.01,0.03,0.05,0.07,0.1,0.15,0.2]:\n",
    "    LR_score[lr] = modelfit_param(X_train1, y_train1, X_val, y_val,31,5,20,lr,1,1)\n",
    "Model_summary = pd.DataFrame(columns = [\"num_leaves\", \"max_depth\",\"min_data_in_leaf\",\"learning_rate\",\"bagging_fraction\",\"feature_fraction\",\"val_rmse\"])\n",
    "for lr,key in LR_score.items():\n",
    "    param = {\n",
    "        \"num_leaves\" : 31,\n",
    "        \"max_depth\" : 5,\n",
    "        \"min_data_in_leaf\": 20,\n",
    "        \"learning_rate\" : lr,\n",
    "        \"bagging_fraction\" : 1,\n",
    "        \"feature_fraction\" : 1,\n",
    "        \"val_rmse\": key\n",
    "        }\n",
    "    \n",
    "    Model_summary=Model_summary.append(param,ignore_index=True)\n",
    "Model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameter Optimization 2 - max_depth (Fix learning rate=0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.61962\n",
      "Early stopping, best iteration is:\n",
      "[296]\tvalid_0's rmse: 1.61947\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.61869\n",
      "Early stopping, best iteration is:\n",
      "[260]\tvalid_0's rmse: 1.61812\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.61938\n",
      "Early stopping, best iteration is:\n",
      "[207]\tvalid_0's rmse: 1.61824\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_data_in_leaf</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>bagging_fraction</th>\n",
       "      <th>feature_fraction</th>\n",
       "      <th>val_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_leaves  max_depth  min_data_in_leaf  learning_rate  bagging_fraction  \\\n",
       "0        31.0        5.0              20.0           0.01               1.0   \n",
       "1        31.0        5.0              20.0           0.03               1.0   \n",
       "2        31.0        5.0              20.0           0.05               1.0   \n",
       "3        31.0        5.0              20.0           0.07               1.0   \n",
       "4        31.0        5.0              20.0           0.10               1.0   \n",
       "5        31.0        5.0              20.0           0.15               1.0   \n",
       "6        31.0        5.0              20.0           0.20               1.0   \n",
       "7        31.0        6.0              20.0           0.07               1.0   \n",
       "8        31.0        7.0              20.0           0.07               1.0   \n",
       "9        31.0        8.0              20.0           0.07               1.0   \n",
       "\n",
       "   feature_fraction  val_rmse  \n",
       "0               1.0   1.62931  \n",
       "1               1.0   1.62248  \n",
       "2               1.0   1.62169  \n",
       "3               1.0   1.62157  \n",
       "4               1.0   1.62283  \n",
       "5               1.0   1.62426  \n",
       "6               1.0   1.62415  \n",
       "7               1.0   1.61947  \n",
       "8               1.0   1.61812  \n",
       "9               1.0   1.61824  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MD_score = dict()\n",
    "for md in [6,7,8]:\n",
    "    MD_score[md] = modelfit_param(X_train1, y_train1, X_val, y_val,31,md,20,0.07,1,1)\n",
    "for md,key in MD_score.items():\n",
    "    param = {\n",
    "        \"num_leaves\" : 31,\n",
    "        \"max_depth\" : md,\n",
    "        \"min_data_in_leaf\": 20,\n",
    "        \"learning_rate\" : 0.07,\n",
    "        \"bagging_fraction\" : 1,\n",
    "        \"feature_fraction\" : 1,\n",
    "        \"val_rmse\": key\n",
    "        }\n",
    "    \n",
    "    Model_summary=Model_summary.append(param,ignore_index=True)\n",
    "Model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameter Optimization 3 - num_leaves (Fix learning rate=0.07, max_depth=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.62075\n",
      "Early stopping, best iteration is:\n",
      "[228]\tvalid_0's rmse: 1.6195\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.62219\n",
      "Early stopping, best iteration is:\n",
      "[219]\tvalid_0's rmse: 1.61991\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.6226\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's rmse: 1.6207\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.62003\n",
      "Early stopping, best iteration is:\n",
      "[214]\tvalid_0's rmse: 1.61913\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_data_in_leaf</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>bagging_fraction</th>\n",
       "      <th>feature_fraction</th>\n",
       "      <th>val_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>60.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>80.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_leaves  max_depth  min_data_in_leaf  learning_rate  bagging_fraction  \\\n",
       "0         31.0        5.0              20.0           0.01               1.0   \n",
       "1         31.0        5.0              20.0           0.03               1.0   \n",
       "2         31.0        5.0              20.0           0.05               1.0   \n",
       "3         31.0        5.0              20.0           0.07               1.0   \n",
       "4         31.0        5.0              20.0           0.10               1.0   \n",
       "5         31.0        5.0              20.0           0.15               1.0   \n",
       "6         31.0        5.0              20.0           0.20               1.0   \n",
       "7         31.0        6.0              20.0           0.07               1.0   \n",
       "8         31.0        7.0              20.0           0.07               1.0   \n",
       "9         31.0        8.0              20.0           0.07               1.0   \n",
       "10        40.0        7.0              20.0           0.03               1.0   \n",
       "11        60.0        7.0              20.0           0.03               1.0   \n",
       "12        80.0        7.0              20.0           0.03               1.0   \n",
       "13       100.0        7.0              20.0           0.03               1.0   \n",
       "\n",
       "    feature_fraction  val_rmse  \n",
       "0                1.0   1.62931  \n",
       "1                1.0   1.62248  \n",
       "2                1.0   1.62169  \n",
       "3                1.0   1.62157  \n",
       "4                1.0   1.62283  \n",
       "5                1.0   1.62426  \n",
       "6                1.0   1.62415  \n",
       "7                1.0   1.61947  \n",
       "8                1.0   1.61812  \n",
       "9                1.0   1.61824  \n",
       "10               1.0   1.61950  \n",
       "11               1.0   1.61991  \n",
       "12               1.0   1.62070  \n",
       "13               1.0   1.61913  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NL_score = dict()\n",
    "for nl in [40,60,80,100]:\n",
    "    NL_score[nl] = modelfit_param(X_train1, y_train1, X_val, y_val,nl,7,20,0.07,1,1)\n",
    "for nl,key in NL_score.items():\n",
    "    param = {\n",
    "        \"num_leaves\" : nl,\n",
    "        \"max_depth\" : 7,\n",
    "        \"min_data_in_leaf\": 20,\n",
    "        \"learning_rate\" : 0.03,\n",
    "        \"bagging_fraction\" : 1,\n",
    "        \"feature_fraction\" : 1,\n",
    "        \"val_rmse\": key\n",
    "        }\n",
    "    \n",
    "    Model_summary=Model_summary.append(param,ignore_index=True)\n",
    "Model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameter Optimization 4 - bagging_fraction  (Fix learning rate=0.07, max_depth=7, num_leaves=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.61869\n",
      "Early stopping, best iteration is:\n",
      "[260]\tvalid_0's rmse: 1.61812\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.61869\n",
      "Early stopping, best iteration is:\n",
      "[260]\tvalid_0's rmse: 1.61812\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.61869\n",
      "Early stopping, best iteration is:\n",
      "[260]\tvalid_0's rmse: 1.61812\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_data_in_leaf</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>bagging_fraction</th>\n",
       "      <th>feature_fraction</th>\n",
       "      <th>val_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>60.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>80.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_leaves  max_depth  min_data_in_leaf  learning_rate  bagging_fraction  \\\n",
       "0         31.0        5.0              20.0           0.01               1.0   \n",
       "1         31.0        5.0              20.0           0.03               1.0   \n",
       "2         31.0        5.0              20.0           0.05               1.0   \n",
       "3         31.0        5.0              20.0           0.07               1.0   \n",
       "4         31.0        5.0              20.0           0.10               1.0   \n",
       "5         31.0        5.0              20.0           0.15               1.0   \n",
       "6         31.0        5.0              20.0           0.20               1.0   \n",
       "7         31.0        6.0              20.0           0.07               1.0   \n",
       "8         31.0        7.0              20.0           0.07               1.0   \n",
       "9         31.0        8.0              20.0           0.07               1.0   \n",
       "10        40.0        7.0              20.0           0.03               1.0   \n",
       "11        60.0        7.0              20.0           0.03               1.0   \n",
       "12        80.0        7.0              20.0           0.03               1.0   \n",
       "13       100.0        7.0              20.0           0.03               1.0   \n",
       "14        31.0        7.0              20.0           0.07               0.7   \n",
       "15        31.0        7.0              20.0           0.07               0.8   \n",
       "16        31.0        7.0              20.0           0.07               0.9   \n",
       "\n",
       "    feature_fraction  val_rmse  \n",
       "0                1.0   1.62931  \n",
       "1                1.0   1.62248  \n",
       "2                1.0   1.62169  \n",
       "3                1.0   1.62157  \n",
       "4                1.0   1.62283  \n",
       "5                1.0   1.62426  \n",
       "6                1.0   1.62415  \n",
       "7                1.0   1.61947  \n",
       "8                1.0   1.61812  \n",
       "9                1.0   1.61824  \n",
       "10               1.0   1.61950  \n",
       "11               1.0   1.61991  \n",
       "12               1.0   1.62070  \n",
       "13               1.0   1.61913  \n",
       "14               1.0   1.61812  \n",
       "15               1.0   1.61812  \n",
       "16               1.0   1.61812  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BF_score = dict()\n",
    "for bf in [0.7,0.8,0.9]:\n",
    "    BF_score[bf] = modelfit_param(X_train1, y_train1, X_val, y_val,31,7,20,0.07,bf,1)\n",
    "for bf,key in BF_score.items():\n",
    "    param = {\n",
    "        \"num_leaves\" : 31,\n",
    "        \"max_depth\" : 7,\n",
    "        \"min_data_in_leaf\": 20,\n",
    "        \"learning_rate\" : 0.07,\n",
    "        \"bagging_fraction\" : bf,\n",
    "        \"feature_fraction\" : 1,\n",
    "        \"val_rmse\": key\n",
    "        }\n",
    "    \n",
    "    Model_summary=Model_summary.append(param,ignore_index=True)\n",
    "Model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameter Optimization 5 -  feature_fraction (Fix learning rate=0.07, max_depth=7, num_leaves=31, bagging_fraction=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.6203\n",
      "[600]\tvalid_0's rmse: 1.62299\n",
      "Early stopping, best iteration is:\n",
      "[382]\tvalid_0's rmse: 1.61899\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.62128\n",
      "Early stopping, best iteration is:\n",
      "[252]\tvalid_0's rmse: 1.62081\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.61897\n",
      "Early stopping, best iteration is:\n",
      "[246]\tvalid_0's rmse: 1.61841\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_data_in_leaf</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>bagging_fraction</th>\n",
       "      <th>feature_fraction</th>\n",
       "      <th>val_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>60.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>80.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.61899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.62081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.61841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_leaves  max_depth  min_data_in_leaf  learning_rate  bagging_fraction  \\\n",
       "0         31.0        5.0              20.0           0.01               1.0   \n",
       "1         31.0        5.0              20.0           0.03               1.0   \n",
       "2         31.0        5.0              20.0           0.05               1.0   \n",
       "3         31.0        5.0              20.0           0.07               1.0   \n",
       "4         31.0        5.0              20.0           0.10               1.0   \n",
       "5         31.0        5.0              20.0           0.15               1.0   \n",
       "6         31.0        5.0              20.0           0.20               1.0   \n",
       "7         31.0        6.0              20.0           0.07               1.0   \n",
       "8         31.0        7.0              20.0           0.07               1.0   \n",
       "9         31.0        8.0              20.0           0.07               1.0   \n",
       "10        40.0        7.0              20.0           0.03               1.0   \n",
       "11        60.0        7.0              20.0           0.03               1.0   \n",
       "12        80.0        7.0              20.0           0.03               1.0   \n",
       "13       100.0        7.0              20.0           0.03               1.0   \n",
       "14        31.0        7.0              20.0           0.07               0.7   \n",
       "15        31.0        7.0              20.0           0.07               0.8   \n",
       "16        31.0        7.0              20.0           0.07               0.9   \n",
       "17        31.0        7.0              20.0           0.07               1.0   \n",
       "18        31.0        7.0              20.0           0.07               1.0   \n",
       "19        31.0        7.0              20.0           0.07               1.0   \n",
       "\n",
       "    feature_fraction  val_rmse  \n",
       "0                1.0   1.62931  \n",
       "1                1.0   1.62248  \n",
       "2                1.0   1.62169  \n",
       "3                1.0   1.62157  \n",
       "4                1.0   1.62283  \n",
       "5                1.0   1.62426  \n",
       "6                1.0   1.62415  \n",
       "7                1.0   1.61947  \n",
       "8                1.0   1.61812  \n",
       "9                1.0   1.61824  \n",
       "10               1.0   1.61950  \n",
       "11               1.0   1.61991  \n",
       "12               1.0   1.62070  \n",
       "13               1.0   1.61913  \n",
       "14               1.0   1.61812  \n",
       "15               1.0   1.61812  \n",
       "16               1.0   1.61812  \n",
       "17               0.7   1.61899  \n",
       "18               0.8   1.62081  \n",
       "19               0.9   1.61841  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FF_score = dict()\n",
    "for ff in [0.7,0.8,0.9]:\n",
    "    FF_score[ff] = modelfit_param(X_train1, y_train1, X_val, y_val,31,7,20,0.07,1,ff)\n",
    "for ff,key in FF_score.items():\n",
    "    param = {\n",
    "        \"num_leaves\" : 31,\n",
    "        \"max_depth\" : 7,\n",
    "        \"min_data_in_leaf\": 20,\n",
    "        \"learning_rate\" : 0.07,\n",
    "        \"bagging_fraction\" : 1,\n",
    "        \"feature_fraction\" : ff,\n",
    "        \"val_rmse\": key\n",
    "        }\n",
    "    \n",
    "    Model_summary=Model_summary.append(param,ignore_index=True)\n",
    "Model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameter Optimization 6 -  min_data_in_leaf (Fix learning rate=0.07, max_depth=7, num_leaves=31, bagging_fraction=1, feature_fraction=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.61912\n",
      "Early stopping, best iteration is:\n",
      "[207]\tvalid_0's rmse: 1.61849\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.61887\n",
      "Early stopping, best iteration is:\n",
      "[275]\tvalid_0's rmse: 1.61857\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.61989\n",
      "Early stopping, best iteration is:\n",
      "[263]\tvalid_0's rmse: 1.61924\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.62006\n",
      "[600]\tvalid_0's rmse: 1.62208\n",
      "Early stopping, best iteration is:\n",
      "[389]\tvalid_0's rmse: 1.61959\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_data_in_leaf</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>bagging_fraction</th>\n",
       "      <th>feature_fraction</th>\n",
       "      <th>val_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>60.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>80.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.61899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.62081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.61841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_leaves  max_depth  min_data_in_leaf  learning_rate  bagging_fraction  \\\n",
       "0         31.0        5.0              20.0           0.01               1.0   \n",
       "1         31.0        5.0              20.0           0.03               1.0   \n",
       "2         31.0        5.0              20.0           0.05               1.0   \n",
       "3         31.0        5.0              20.0           0.07               1.0   \n",
       "4         31.0        5.0              20.0           0.10               1.0   \n",
       "5         31.0        5.0              20.0           0.15               1.0   \n",
       "6         31.0        5.0              20.0           0.20               1.0   \n",
       "7         31.0        6.0              20.0           0.07               1.0   \n",
       "8         31.0        7.0              20.0           0.07               1.0   \n",
       "9         31.0        8.0              20.0           0.07               1.0   \n",
       "10        40.0        7.0              20.0           0.03               1.0   \n",
       "11        60.0        7.0              20.0           0.03               1.0   \n",
       "12        80.0        7.0              20.0           0.03               1.0   \n",
       "13       100.0        7.0              20.0           0.03               1.0   \n",
       "14        31.0        7.0              20.0           0.07               0.7   \n",
       "15        31.0        7.0              20.0           0.07               0.8   \n",
       "16        31.0        7.0              20.0           0.07               0.9   \n",
       "17        31.0        7.0              20.0           0.07               1.0   \n",
       "18        31.0        7.0              20.0           0.07               1.0   \n",
       "19        31.0        7.0              20.0           0.07               1.0   \n",
       "20        31.0        7.0              15.0           0.07               1.0   \n",
       "21        31.0        7.0              25.0           0.07               1.0   \n",
       "22        31.0        7.0              30.0           0.07               1.0   \n",
       "23        31.0        7.0              35.0           0.07               1.0   \n",
       "\n",
       "    feature_fraction  val_rmse  \n",
       "0                1.0   1.62931  \n",
       "1                1.0   1.62248  \n",
       "2                1.0   1.62169  \n",
       "3                1.0   1.62157  \n",
       "4                1.0   1.62283  \n",
       "5                1.0   1.62426  \n",
       "6                1.0   1.62415  \n",
       "7                1.0   1.61947  \n",
       "8                1.0   1.61812  \n",
       "9                1.0   1.61824  \n",
       "10               1.0   1.61950  \n",
       "11               1.0   1.61991  \n",
       "12               1.0   1.62070  \n",
       "13               1.0   1.61913  \n",
       "14               1.0   1.61812  \n",
       "15               1.0   1.61812  \n",
       "16               1.0   1.61812  \n",
       "17               0.7   1.61899  \n",
       "18               0.8   1.62081  \n",
       "19               0.9   1.61841  \n",
       "20               1.0   1.61849  \n",
       "21               1.0   1.61857  \n",
       "22               1.0   1.61924  \n",
       "23               1.0   1.61959  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MDIL_score = dict()\n",
    "for mdil in [15,25,30,35]:\n",
    "    MDIL_score[mdil] = modelfit_param(X_train1, y_train1, X_val, y_val,31,7,mdil,0.07,1,1)\n",
    "for mdil,key in MDIL_score.items():\n",
    "    param = {\n",
    "        \"num_leaves\" : 31,\n",
    "        \"max_depth\" : 7,\n",
    "        \"min_data_in_leaf\": mdil,\n",
    "        \"learning_rate\" : 0.07,\n",
    "        \"bagging_fraction\" : 1,\n",
    "        \"feature_fraction\" : 1,\n",
    "        \"val_rmse\": key\n",
    "        }\n",
    "    \n",
    "    Model_summary=Model_summary.append(param,ignore_index=True)\n",
    "Model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.61927\n",
      "Early stopping, best iteration is:\n",
      "[201]\tvalid_0's rmse: 1.61901\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.61984\n",
      "Early stopping, best iteration is:\n",
      "[213]\tvalid_0's rmse: 1.61871\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.62533\n",
      "[600]\tvalid_0's rmse: 1.62704\n",
      "Early stopping, best iteration is:\n",
      "[371]\tvalid_0's rmse: 1.62391\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.64503\n",
      "Early stopping, best iteration is:\n",
      "[289]\tvalid_0's rmse: 1.64491\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.60785\n",
      "[600]\tvalid_0's rmse: 1.6083\n",
      "Early stopping, best iteration is:\n",
      "[385]\tvalid_0's rmse: 1.60676\n",
      "1.62266 [  3.15262098e-03   1.04251258e-03   4.20521517e-03 ...,   6.08186770e-01\n",
      "  -1.43363178e-01  -1.15491478e+00]\n"
     ]
    }
   ],
   "source": [
    "def modelfit_cv(X_train1, y_train1, X_val_c, y_val_c, X_test):\n",
    "    train_data = lgb.Dataset(X_train1, label=y_train1)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "    params = {\n",
    "    \"objective\" : \"regression\",\n",
    "    \"metric\" : \"rmse\", \n",
    "    \"num_leaves\" : 31,\n",
    "    \"max_depth\" : 7,\n",
    "    \"min_data_in_leaf\": 20,\n",
    "    \"learning_rate\" : 0.07,\n",
    "    \"bagging_fraction\" : 1,\n",
    "    \"feature_fraction\" : 1\n",
    "    }\n",
    "\n",
    "    bst = lgb.train(params, train_data, 1000, valid_sets=[val_data], early_stopping_rounds=300, verbose_eval=300)\n",
    "\n",
    "    pred_val = bst.predict(X_val, num_iteration=bst.best_iteration)\n",
    "    val_rmse=round(np.sqrt(metrics.mean_squared_error(y_val, pred_val)),5)\n",
    "    y_test_pred = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "    return(val_rmse,y_test_pred)\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "val_score = []\n",
    "y_pred = []\n",
    "for train_index, val_index in kf.split(X_train, y_train):\n",
    "    X_train1, X_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train1, y_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    score,y_test_pred = modelfit_cv(X_train1, y_train1, X_val, y_val,X_test)\n",
    "    \n",
    "    val_score.append(score)\n",
    "    y_pred.append(y_test_pred)\n",
    "val_rmse_5fold = round(np.mean(val_score),5)\n",
    "y_pred_5fold = np.mean(y_pred,axis=0)\n",
    "\n",
    "print(val_rmse_5fold,y_pred_5fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalize Prediction Results and Visualize Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user ID</th>\n",
       "      <th>pred_rev_log</th>\n",
       "      <th>pred_rev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6167871330617112363</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>1.003158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0643697640977915618</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>1.001043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6059383810968229466</td>\n",
       "      <td>0.004205</td>\n",
       "      <td>1.004214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2376720078563423631</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>1.000831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2314544520795440038</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>1.001177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user ID  pred_rev_log  pred_rev\n",
       "0  6167871330617112363      0.003153  1.003158\n",
       "1  0643697640977915618      0.001043  1.001043\n",
       "2  6059383810968229466      0.004205  1.004214\n",
       "3  2376720078563423631      0.000831  1.000831\n",
       "4  2314544520795440038      0.001176  1.001177"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_pred = pd.DataFrame(columns = ['user ID', 'pred_rev_log'])\n",
    "customer_pred['user ID'] = test.fullVisitorId\n",
    "customer_pred['pred_rev_log'] = y_pred_5fold\n",
    "customer_pred['pred_rev'] = customer_pred['pred_rev_log'].apply(lambda x: np.exp(x) if x>0 else 0)\n",
    "customer_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user ID</th>\n",
       "      <th>Sum_revenue_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>259678714014</td>\n",
       "      <td>0.833565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3038793126460</td>\n",
       "      <td>0.002659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9663019041506</td>\n",
       "      <td>0.002542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10438463470860</td>\n",
       "      <td>0.003260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10992980461157</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user ID  Sum_revenue_log\n",
       "0    259678714014         0.833565\n",
       "1   3038793126460         0.002659\n",
       "2   9663019041506         0.002542\n",
       "3  10438463470860         0.003260\n",
       "4  10992980461157         0.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final = customer_pred.groupby('user ID')['pred_rev'].sum().reset_index(name='Sum_revenue')\n",
    "Final['Sum_revenue_log']=Final['Sum_revenue'].apply(lambda x: np.log(x) if x>0 else 0)\n",
    "Final.drop(columns='Sum_revenue', inplace=True)\n",
    "Final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[300]\tvalid_0's rmse: 1.60785\n",
      "[600]\tvalid_0's rmse: 1.6083\n",
      "Early stopping, best iteration is:\n",
      "[385]\tvalid_0's rmse: 1.60676\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAQXCAYAAACOMJiaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAIABJREFUeJzs3XmYXvP9//HnZEVDEBJ7Q/C2k0aqFC0lpETspVq0lrbUrogoamtspcrX0pbQWqOIpNQSa+1ijeVtKV/1bSy/ECKym98f5yS9jRlZJLlPkufjunLNPed8zue8zz3DNa95f86ZhsbGRiRJkiRJ1dGq3gVIkiRJkj7PoCZJkiRJFWNQkyRJkqSKMahJkiRJUsUY1CRJkiSpYgxqkiRJklQxbepdgCRp/hURJwO/zMylWtj/XeBeYN3MHDET8+4LXAEsmpmffMm4A4H3MvOWZva1Bw4CfgisAbQD3gKGAX/IzBfKcV2BN2oO/Qz4P+AO4PjMfL9mzvuA7wB/zsz9m5xvReB/gQZgi8y8b0av90uub+r5mvp1Zp72Vedvcq4W38t6iIhG4JDMvLDetUxPRLQDjgduycxn6l2PpHmDHTVJUj09BWwMvD6H5j8Q2LHpxohYhCKQnUwRuHYFtgUuADYB/tHMXEeXtW4OnALsAFzdzLhPgJ0jom2T7XsAY2flIqbj3rKu2n9XzIHzNPteaoa0A04CNqh3IZLmHXbUJEl1k5kfA4/W4dSnU/zQvNHUzlnp3oi4CNivmWMyM6fW+lDZJbkwIjo06erdD2wGbAMMrdm+B3ArRQdvdvqgpq55RkQslJnj613HnBYRC9e7BknzJoOaJKlumlv6GBFLABcDfYCPgN8DSwO7ZmbXJlOsHBG/o+iC/ZtiKeJN5Tz3AT2AHhGxTzn+J8ANFN2hi5qENAAy8zPgjzNQ/hiKZYytm2wfDwymCGZDy1pWA75B0cGb3UHtS0XEksAAoC/QkaKLeURmPlYz5qiy3tUp6n+8HPNauf8+mnkvM3Ngc0sQmy55rVmquhFwVvnxDODUiFiIokO5J9AZeBnol5m3zeR13gf8P+DvwIkU3zM3A/sD6wMXAmsBTwJ7Z+Zb5XFdKZa27gX0pugajqP4/vhNk3NsCfy2nO8j4G/AMVODes3387bAwcCWwPXAT8sproiIqd3OlTPzzYgYAGwHrAyMpgj6R2XmOzXnfRO4kWLJ7VHA1yg6wT/PzNE14zpRvK87AEtQLLW9ODPPL/e3Ao4p35OpS3FPz8wrZ+xdljQ3ufRRklQ1A4GtgcMoAlUv4ActjL2Goku1E/AqcF1ErFDuO4jih/7b+O+SwL9TBI5FgDtnsq5WEdEmItpHxPrAr4B7M/OjZsZeC/St6absCTzG5+91m10ayrqm/Zu6o7wP725gq7LeHYH3gbsjYpmaOVakCMc7AQdQhM+HI6Jjub+l93JmXQsMAb7Pf7uNNwL7UgSMPsATwK0RMSvLBL8F7AMcQhFIdgf+QBG8fw/8CFgFuKyZY88GPqVYBvtH4KSIOHjqzohYm2JJ7P8DdqFYyvjDsv6m/gw8SxGY/kwR2ABO47/v38hy2zLAmcD2wOFlffeUoarW7sD3KP6bOLYcf0ZNfQsD91F8jU+leI/PBZarmeMPwAnl9W9HEWQvj4jtm7kGSXVmR02SVBkRsQ7FD7e7Z+agctswim5Zcw8NOS8zLy/HDQfepfgB9pLMfDEixgLv1y4NLLsilHPWnrsVNb/AzMzJTc41uMnnLwI/buFS7gImlLUMogiaM9KlmxU7A5NqN0RE27L+HwHrAGtn5qvlvruBpOjM/AogMw+vObZ1Wf97FF24q1p6L2fBBZn5+5pzfY8iMHw3M+8vN98ZEasD/YHdZnL+DkDfqeG57HAdAHwnMx8oty0HXBQRi2TmpzXHvpCZPytf3xERnYHjI+Lissv6a4oO1A6ZOaWc6wPg+ojYODMfqZlrUGb+uuY6O5QvX2/6/mXmvjXjWgOPAG8DmwIP1AydBOw49fsyItai6IIeVO7fG1gb+EbNA0vuqZl7VeAXFJ3QqR20uyNiWYrQWbtMV1IF2FGTJFXJhuXHIVM3ZOY4iq5Qc+6sGTeKIlys0MLYphqbfH4rxQ/Dk4BJZWisdQTQE/gmRefpY+D2mh/Cpyl/mP4bsEdErEfxVMkbZqSoiGjdpEPWMJ1D7inrmvavJmRuBQwH3mjSbbuf/77XRMS3IuKuiBgFTKboLHWgWAo5OzXtwm0FvENxz19tR3BYbX0z4ckmHc7XgInAP5tsg893mqDoLtW6qRwz9fvpm8DNU0Na6W8U79emTY6d4W5jRPSOiIcj4qNyrrfLXU3f+3ub/PLgRaBzzUNrtgSe/pKnSn6P4omlNzfzXm9QhkRJFWJHTZJUJcsAY5p5yMT7zQ2muKen1kRgoemc4z/lxxWAV2q2H05xD1kP4JJmjnstM58sXz8REQ9RhIx9Ke5/auo6iqWCI4EHM/M/5f1i0zOMzz9yfwuKJW0t+bCmrqaWolgOOKmZfa8DRMRKFIH3ceBnFO/PRIqwMb33cma920x9y7RQ35Rmtk1Pc98PY8qOWO02+OK1vdfC58tS/NmGZWlSf2ZOKcNt069r0+tsVkT0pPgFwc0U9xG+R/ELhEebqa+5a2sA2lO8f53473LK5ixFsaS1uaW6UFzf2y3sk1QHBjVJUpW8AyzazBMBl56N5xhO0THqRc3SsJoHZ3yhQ9aczHw/Iv4fsGYLQ+4HPqRYbnZwC2Oa8zNg0dpTzcSxTX1A8fCMXzSzb0L5cVuKe/b6ZuZYgLLTMiOhcuo87ZpsW6KFsU27mB9QPCCjCo/979zC5yNrPn5uTNmF6kRxHbWaXmdLdqL4JcQPMrOxnPPrM1pwE6OAVb9k/wcUHbtvU3TWmmoaVCXVmUFNklQlUztDO1AuFSwfkrA1xVMWZ9YXOmyZ+WlEXAYcHBFXZuZLs1JoRHSh6FL8u7n9mflZRJxBsbyvuQdONCszv0owa2oYRSB9KzNb+kF8YYof3GuX1e3OF39GaKlb+TY1YbW81+97M1HfUcAnmfnyDB4zp+xE8UCVqXamCGdTu0yPATtFxPE1yx93pnifapdWNqelLt7CwKSpIa2018wWXhoG7BYR62Xmc83sv4eio9YxM++axXNImosMapKkOa1dROzazPb7m27IzBERMQS4OCIWpeiwHUnRAWuuCzA9LwPbRMQ2FB2HN8p72fpT3HP0SERcCDxI8Vj65SmeGjiF4hHttaLsoDWU435FER6vbenk5SPrm1sWObdcBfwcuC8izgH+RdEB+ibwTmaex39/gL8iIv5M8UCKo/niUruW3subKULv0+X8+wOLzWB9d1E8Zv6uiDgTeKE8dgNgoczsN2uXPUvWjohLKe4725zib+kdVrNs8jTgaeCWiLiYYunsmcAdTR4k8gWZOTEi3gB2j4gRFN9rz1Fc/+ERcT7FfZmbUDwAZlZcRdG5vbP88whJ8cj/1TPzuMzMiLiE4smoZ1H8UmQhiq/36pm5/yyeV9Ic4sNEJElz2qIUTz5s+m/tFsbvS/HwkAuAyykC3T8oHt4xs04DXqLozj1B8fh3yqf9bUnx97u2pfjh/A7gNxSP0F8/M19vMtc5FE/ke5gifL1P8bTC/52FuuaKcvnoFhSB4DcU96L9HliN4p40MvN5ivd8I4on//2Q4mmLTe9lava9LOcdVO4fCDxD8TfTZqS+Roqu1OUU9wjeAVxK8fj66XWpZrdjKELi3yiWn55KTcgu/+Zeb4rljzdRXO+1FI/znxE/p+jA3k3x/i1X/q24Yyke938rxb2Js/So/PJrvSVF4DsFuL28pv/UDDu4vK69Ke6fHEjx1M3ap0tKqoiGxsYZXUYtSdLcV94vNQJ4LDP3md54aWbU/MHrPpnpI+olVYZLHyVJlRIRu1E8Fv15ig7HARQdoL3rWZckSXOTQU2SVDVjgZ9QPMGuNUVg65OZj9e1KkmS5iKXPkqSJElSxfgwEUmSJEmqGJc+aoE1fPjw9kBPir+TM2U6wyVJkqRZ0RpYFniiR48eE2b0IIOaFmQ9Kf52kiRJkjSnbcZM/OkRg5oWZCMBVl99ddq1a1fvWiRJkjQfmjhxIq+88gqUP3vOKIOaFmRTANq1a0f79u3rXYskSZLmbzN1q40PE5EkSZKkijGoSZIkSVLFGNQkSZIkqWIMapIkSZJUMQY1SZIkSaoYg5okSZIkVYxBTZIkSZIqxqAmSZIkSRVjUJMkSZKkijGoSZIkSVLFGNQkSZIkqWIMapIkSZJUMQY1SZIkSaoYg5okSZIkVYxBTZIkSZIqxqAmSZIkSRVjUJMkSZKkijGoSZIkSVLFGNQkSZIkqWIMapIkSZJUMQY1SZIkSaoYg5okSZIkVYxBTZIkSZIqxqAmSZIkSRVjUJMkSZKkijGoSZIkSVLFGNQkSZIkqWIMapIkSZJUMQY1SZIkSXPVxElT6l1C5bWpdwFSve1/+l2MHuv/LCRJkuaWIef2rXcJlWdHTZIkSZIqxqAmSZIkSRVjUJMkSZKkijGoSZIkSVLFGNQkSZIkqWIMapIkSZJUMQY1SZIkSaoYg5okSZIkVYxBTZIkSZIqxqAmSZIkSRVjUJMkSZKkijGoSZIkSVLFGNQkSZIkqWIMapIkSZJUMW3qXYAkSZKkBc/IkSM55phjGDVqFA0NDey+++7ss88+jB49miOOOIL/+7//Y/nll+f888+nY8eOTJo0iRNOOIEXX3yRyZMns+OOO/Kzn/0MgKFDh3LppZcC0LlzZ84++2yWXHLJel7eV2ZHbS6JiJMjot0MjDs8IjrP4Jz3RcT2X726uSsidoiIs+tdhyRJkuqndevWHHfccdx2221cf/31XHPNNbz22mtcdtllbLzxxtx5551svPHGXHbZZQD84x//YOLEiQwZMoSbbrqJ66+/nrfffpvJkydz+umnc+WVVzJkyBAigquvvrrOV/fVGdTmnpOA6QY14HBghoLavCozb83MX9W7DkmSJNVP586dWXvttQHo0KEDq6yyCu+++y7Dhg1jxx13BGDHHXfk7rvvBqChoYFx48YxefJkxo8fT9u2benQoQONjY00NjYybtw4Ghsb+eSTT+jced7/cdqlj3NBRFxUvnw4Ij4DtgEuAboBDcDZmXlVRPQHlgNujIjxwA+BZYHTgIUovl6nZ+Z1zZzjQOAIYAJFAN89M19uMuZkYC1gqfI8LwA/zcyPIuJ7LZ0nItYCrgC+BjwDrAqclplDI2JZ4A/ASsDCwLWZeUZE/AjYJTN3KudoA7wFfBv4DrB9Zu5a7tsHOKg870fALzIzI+IR4NDMfCIi/gf4TmauXc71DvB1YH3gwvKa25Z1XTvDXxxJkiTV3dtvv81LL73E+uuvz6hRo6YFraWXXppRo0YBsM022zBs2DA23XRTxo8fT79+/Vh88cUBOPnkk+nTpw+LLLIIX//61znppJPqdi2zix21uSAzDy5fbpKZGwAXACMycz2gFzAgItbJzNOB/wC7ZuYGmfki8BSwaWZ2B7YCzomIJZo5zdnAluX8PSlCUXM2A/bMzDUoQtGvy+1fdp6/AH/IzHWA88v5p7oKuCAzvwn0AHpHxNbATcBmEbFUOa438HJmvlFbTERsBuwObJ6ZPcrruLzcPQz4Xvl6U2BcGQx7Ai9l5ljgWIqguwGwDnB7C9ctSZKkCho7diyHHnooxx9/PB06dPjcvoaGBhoaGgB47rnnaNWqFQ8++CDDhg3j8ssv59///jeTJk3i2muv5ZZbbuHBBx8kIqbdrzYvM6jVx1bApQCZORK4DdiihbFLU3TYRgB3AEsC0cy4e4ArI+IQYPnM/LSF+YZm5rvl6z8DW37ZeSJiMYoAdE1Z75PAcxQ7vwZ8F7ggIp4BHqfo1K1Znv8Wiq4gwL7AwGbq6UPRFXusnGMAsGK5bxiwVUSsCIwChlIEt63K6wW4FzghIk4AvpmZo1u4bkmSJFXMpEmTOPTQQ+nTpw+9evUCoFOnTrz33nsAvPfee9MeCjJ06FA222wz2rZtS6dOnfjGN77B888/z0svvQTASiutRENDA7179+bpp5+uzwXNRga16rsYuA9Yt+wavU2xPLGpnYETKJYn3hsRvWfzeRqbOaZVub1n2QHcIDO7ZeYF5f6BwD4R0YliueONzczRAFxec/z6mblSue9h4BvAdhShbWqH7XvlazLzfGAH4H3gDxFx2kxetyRJkuqgsbGR/v37s8oqq/CTn/xk2vYtt9ySW265BYBbbrmF732vWGC17LLL8thjjwHw6aef8uyzz7LKKqvQpUsXXn/9dT744AMAHnroIbp16zaXr2b2M6jNPWOAjuXru4EDACJiGeD7/LdD9HHNOIDFgTczs7FcUrhq04nLe7ZWyczHM3MAcCfQvYU6touIpcvXP6k5b7PnycyPKe5l27M81zeAdct9Y4AHgeNqalmxvCYy85/AYsBvgVta6PINAfaOiBXK41tHRI/y+AkUSzKPK9+zRynucVuvfE1ErJ6Zr2fmpcDvgW+2cN2SJEmqkOHDhzN48GAeffRR+vbtS9++fbn//vs58MADeeihh+jVqxcPP/wwBx54IAB77bUXY8eOZbvttmPXXXdl5513Zo011qBLly4cfPDB7LXXXvTp04eXX3552mP752U+TGTuORe4JyLGUTxM5NKIeI6io3RcZr5QjrsAuCIiPqVYNngc8D8R8RvgCcplh020BgZGxOLAZ8C/y+OIiD8Bt2bmreXYB4HrImJ54EXgqHL7l51nb+DyiOgHPF/++6jctxdwXkQ8X34+BvgpxcM+AK4ETqW4N+4LMvOB8iEqt0ZEa4onYw4ChpdDhlHck/ZEZk6JiNeANzJzYrn/0IjYAphI8SCVQ5o7jyRJkqplww03JDOb3XfllVd+YdvXvvY1LrjggmZGw5577smee+45W+urt4bGxuZWtGl+VD71sUNmHj2Tx3UAxpbdtrUolkhGZn44+6uce4YPH94VeOP8wSMZPXZKvcuRJElaYAw5t2+9S5hrJkyYwIgRIwBW7tGjx5szepwdNc2ITYCzI6Kh/PyAeT2kSZIkSVVmUFuAZObJs3jcnRT3vUmSJEmaC3yYiCRJkiRVjEFNkiRJkirGoCZJkiRJFWNQkyRJkqSKMahJkiRJUsUY1CRJkiSpYgxqkiRJklQxBjVJkiRJqhiDmiRJkiRVjEFNkiRJkirGoCZJkiRJFWNQkyRJkqSKMahJkiRJUsW0qXcBUr39qf/WtG/fvt5lSJIkLTAmTppCu7at611GpdlRkyRJkjRXGdKmz6AmSZIkSRVjUJMkSZKkijGoSZIkSVLFGNQkSZIkqWIMapIkSZJUMQY1SZIkSaoYg5okSZIkVYxBTZIkSZIqxqAmSZIkVczESVPqXYLqrE29C5Dqbf/T72L0WP9nKEmSqmPIuX3rXYLqzI6aJEmSJFWMQU2SJEmSKsagJkmSJEkVY1CTJEmSpIoxqEmSJElSxRjUJEmSJKliDGqSJEmSVDEGNUmSJEmqGIOaJEmSJFWMQU2SJEmSKsagJkmSJEkVY1CTJEmSpIoxqEmSJElSxRjUJEmSJKliDGqSJElSRfXr14+NN96Y7bffftq2l156id13352+ffuy884789xzzwEwceJE+vXrR58+fdhhhx147LHHph0zdOhQ+vTpQ58+fdhvv/344IMP5vq1aOYY1CRJkqSK2nnnnfnTn/70uW1nn302Bx98MIMHD+awww7j7LPPBmDQoEEADBkyhCuuuIIzzzyTzz77jMmTJ3P66adz5ZVXMmTIECKCq6++eq5fi2aOQU2VFRGNEdGh3nVIkiTVS8+ePenYsePntjU0NDB27FgAxowZQ+fOnQF47bXX2GijjQDo1KkTiy66KCNGjKCxsZHGxkbGjRtHY2Mjn3zyybRjVF1t6l2AJEmSpBl3/PHHs99++03rmF133XUArLHGGtxzzz1sv/32jBw5khdeeIGRI0ey3nrrcfLJJ9OnTx8WWWQRvv71r3PSSSfV+So0PQY1fUFENAInADsCnYADgK2AbYG2wG6Z+VI59ljgx+WhTwCHZOYnEXEyEEBHYBXg9fK4T7/kvDsDZwDjgb812Xd1OV974DXgp5n5YUT8HRiYmYNq5vh5Zvb6qu+DJElSFV177bX069ePbbbZhttuu43+/fszcOBAdtllF15//XV22WUXlltuObp3707r1q2ZNGkS1157Lbfccgsrrrgip556KpdeeikHHXRQvS9FX8Klj2rJ6MzsCRwLDAYeyszuwFVAf4CI6E0R0jYB1gVaA7+umWND4IfAmhQBb6+WThYRXYA/An0zcwNgQpMhh2Xmhpm5LvBCWRfAH4Da/8scDFw001crSZI0j7j55pvp1av4nXTv3r2nPUykTZs2HH/88QwePJiLL76YMWPG0LVrV1566SUAVlppJRoaGujduzdPP/103erXjDGoqSXXlx+fAhozc2j5+XBg1fL1VsB1mflxZjYCl5XbprojM0eX+x4Dun3J+TYCnsrMLD+/rMn+vSNieEQ8TxH+Nph6DmDZiFgzItYszzEUSZKk+VTnzp15/PHHAXj00Ufp2rUrAOPGjePTT4vFSw899BCtW7dm1VVXpUuXLrz++uvTnvT40EMP0a3bl/1Ypipw6aNaMr78OIXPd7emMOPfN+NrXk8BFp6VQiJiM+AXwCaZ+X5E/BA4ECAzGyPiQv7bVbs0M6fMynkkSZKq5sgjj+Txxx/nww8/ZPPNN+eQQw7h1FNP5YwzzmDy5Mm0b9+eU045BYBRo0ax33770apVK7p06cJZZ50FQJcuXTj44IPZa6+9aNOmDcsvvzy//e1v63lZmgEGNX0VdwNnRcTvgU+A/YG7ZnGuR4HLI2K1zHy1nGuqxYGPgFER0R74aZNjrwRepLh/be1ZPL8kSVLl/O53v2t2+0033fSFbSussAJ33HFHs+P33HNP9txzz9lam+Yslz5qlmXm7cBfgUeA58vNp83iXO9RdMmGRMTTwEI1u/9B8TCSV4D7KZZj1h47phxzZ2a+PyvnlyRJkqqkobGxsd41SF9JRLQBngP2ycwnZvS44cOHdwXeOH/wSEaPdbWkJEmqjiHn9q13CZpNJkyYwIgRIwBW7tGjx5szepwdNc3TImIHim7bnTMT0iRJkqQq8x41zVURcSKwczO7epXLH2dKZt4K3PqVC5MkSZIqxKCmuSozTwFOqXcdkiRJUpW59FGSJEmSKsagJkmSJEkVY1CTJEmSpIoxqEmSJElSxRjUJEmSJKliDGqSJEmSVDEGNUmSJEmqGIOaJEmSJFWMQU2SJEmSKsagJkmSJEkVY1CTJEmSpIppU+8CpHr7U/+tad++fb3LkCRJmmbipCm0a9u63mWojuyoSZIkSRVjSJNBTZIkSZIqxqAmSZIkSRVjUJMkSZKkijGoSZIkSVLFGNQkSZIkqWIMapIkSZJUMQY1SZIkSaoYg5okSZIkVYxBTZIkSZIqxqAmSZIktWDipCn1LkELqDb1LkCqt/1Pv4vRY/2fsCRJ+qIh5/atdwlaQNlRkyRJkqSKMahJkiRJUsUY1CRJkiSpYgxqkiRJklQxBjVJkiRJqhiDmiRJkiRVjEFNkiRJkirGoCZJkiRJFWNQkyRJkqSKMahJkiRJUsUY1CRJkiSpYgxqkiRJklQxBjVJkiRJqhiDmiRJkiRVTJt6FyBJkiRVXb9+/bjvvvvo1KkTQ4cOBeDwww/njTfeAGDMmDEsuuiiDB48mIkTJ3LSSScxYsQIGhoa6N+/PxtttBEAEydO5NRTT+Xxxx+noaGBI444gm222aZu16XqMqiJiDgZOCMzJ05n3OHANZn53gzMeR9wTmYOnYkaOmTm0c3s+zmwcGaeFxEbAKtn5g0zMq8kSdLssPPOO/OjH/2IY489dtq2888/f9rrAQMG0KFDBwAGDRoEwJAhQxg1ahQHHHAAN954I61ateKSSy5hySWX5I477uCzzz5j9OjRc/dCNM9w6aMATgLazcC4w4HOc7iWL8jMSzLzvPLTDYDd53YNkiRpwdazZ086duzY7L7GxkZuv/12tt9+ewBee+21aR20Tp06seiiizJixAgA/va3v/Gzn/0MgFatWrHkkkvOheo1L7KjtoCLiIvKlw9HxGfANsAlQDegATg7M6+KiP7AcsCNETEe+CGwLHAasBDF99LpmXldM+c4EDgCmEDxy4HdM/PlZspZPiJuA1YBXgd2y8xPp3bbgN8CpwCLRcQzwAPAccCVwNrAJCAz0yAnSZLmmieffJJOnTrRtWtXANZYYw3uuecett9+e0aOHMkLL7zAyJEjp+3//e9/z+OPP86KK67IiSeeyFJLLVW/4lVZdtQWcJl5cPlyk8zcALgAGJGZ6wG9gAERsU5mng78B9g1MzfIzBeBp4BNM7M7sBVwTkQs0cxpzga2LOfvCbzVQjkbUgTANYG2wF5Nah0FnAjcXdZwKEWwXCwz18rM9YGfzeJbIUmSNEuGDh06rZsGsMsuu7DMMsuwyy67cMYZZ9C9e3dat27N5MmTeeedd+jevTs333wz3bt358wzz6xj5aoyO2pqaivgKIDMHFl2uLYARjQzdmng8ohYDZgMLAkE8GiTcfcAV0bEEODvmfmvFs59R2aOBoiIxyi6etPzLLBm2Rm8D/j7DBwjSZI0W0yePJm77rqLm266adq2Nm3acPzxx0/7fI899qBr164sscQSLLzwwvTq1QuAbbfdlhtvvHGu16x5gx01fRUXU4Sjdctu2dsUyyCb2hk4AfgacG9E9G5hvvE1r6cwA79IKEPf2sBdFCHz2YhorgZJkqTZ7uGHH2aVVVZhmWWWmbZt3LhxfPrppwA89NBDtG7dmlVXXZWGhga22GILHnvsMQAeeeQRunWbkd9La0FkUBPAGGDq3bF3AwcARMQywPcpOmIAH9eMA1gceDMzGyNia2DVphNHRBtglcx8PDMHAHcC3b9CrZ+rISJWAKZk5i0U98EtTdHZkyRJmm2OPPJI9thjD9544w0233zzaU92vO2229huu+0+N3YPkOEAAAAgAElEQVTUqFHstNNO9O7dmz/+8Y+cddZZ0/YdffTRXHjhhfTp04fBgwdz3HHHzdXr0LzDpY8COBe4JyLGUdzzdWlEPEfxMJHjMvOFctwFwBUR8SnFvWTHAf8TEb8BngCea2bu1sDAiFgc+Az4d3kcEfEn4NbMvHUmah0GHB0RzwL3A7dT3Ec39Vy/zcz/zMR8kiRJ0/W73/2u2e0DBgz4wrYVVliBO+64o9nxyy+/PFdfffVsrU3zp4bGxsZ61yDVxfDhw7sCb5w/eCSjx06pdzmSJKmChpzbt94laB43YcKEqX+eYeUePXq8OaPHufRRkiRJkirGoCZJkiRJFWNQkyRJkqSKMahJkiRJUsUY1CRJkiSpYgxqkiRJklQxBjVJkiRJqhiDmiRJkiRVjEFNkiRJkirGoCZJkiRJFWNQkyRJkqSKMahJkiRJUsUY1CRJkiSpYgxqkiRJklQxBjVJkiRJqpg29S5Aqrc/9d+a9u3b17sMSZJUQRMnTaFd29b1LkMLIDtqkiRJUgsMaaoXg5okSZIkVYxBTZIkSZIqxqAmSZIkSRVjUJMkSZKkijGoSZIkSVLFGNQkSZIkqWIMapIkSZJUMQY1SZIkSaoYg5okSXPAxElT6l2CJGke1qbeBUj1tv/pdzF6rD9QSZq9hpzbt94lSJLmYXbUJEmSJKliDGqSJEmSVDEGNUmSJEmqGIOaJEmSJFWMQU2SJEmSKsagJkmSJEkVY1CTJEmSpIoxqEmSJElSxRjUJEmSJKliDGqSJEmSVDEGNUmSJEmqGIOaJEmSJFWMQU2SJEmSKsagJkmSJEkVY1CTJGkOuvLKK9l+++3ZbrvtGDhw4LTtf/nLX9h2223ZbrvtOOusswD48MMP+fGPf0z37t055ZRT6lSxJKkK2tS7AM15EfFzYOHMPO9LxpwCvJCZ10fEd4F2mXlnzf5G4B+Z2bvJtkUz85PZVOd3gXMyc8PZMZ8k1dsrr7zCoEGDGDRoEG3btmX//fdniy22YOTIkQwbNoxbb72Vdu3aMWrUKADat2/PYYcdxquvvsqrr75a5+olSfVkUFsAZOYlMzDmxJpPvwt0AO5sMmyNiNg8Mx+YjeXNdhHROjOn1LsOSXr99ddZb731WHjhhQHo2bMnd955JyNGjODAAw+kXbt2AHTq1AmARRZZhA033JC33nqrbjVLkqrBoDYfiYgTgE6ZeUT5eScggSuAhsw8OiI2AS6kWPbaFjgtM6+NiIHAk8D9wM+BVhGxFXBdZg4oT3EyMADYpJlzf667Vvt5+foEYEegE3AAsBWwbVnDbpn5UjlV24i4CugBjAX2zcwXyzn3AQ6i+L79CPhFZmZE7Av8CBgDrFa+fuarvJeSNDusvvrqnH/++Xz44YcstNBCPPDAA6yzzjq8+eabPPnkk5x33nm0b9+eY445hvXWW6/e5UqSKsR71OYvVwF7RMTUAP5D4FaKwDPVscDZmbkBsA5we+0Emfk8cAlwVWZuUBPSAP4GtImIvrNQ2+jM7FmefzDwUGZ2L2vuXzNuPeDPmbk2cFG5n4jYDNgd2DwzewBnA5fXHPct4OjMXCczDWmSKqFbt27sv//+7Lfffuy///6sscYatGrViilTpvDRRx9xww03cMwxx3D44YfT2NhY73IlSRViUJuPZOZbwAvA98tN+wIDmwy7Fzih7L59MzNHz+RpjgdOi4iZ/d65vvz4FNCYmUPLz4cDq9aMey0z7y9f/wVYNyIWA/oA6wOPRcQzFJ29FWuO+2dmvj6TNUnSHLfbbrtx0003cfXVV9OxY0e6du1Kly5d2HrrrWloaGC99dajVatWfPjhh/UuVZJUIQa1+c9AYJ+IWBfoCDxYuzMzzwd2AN4H/hARp83M5Jl5N/AuxfLCWlMov58iYqFmDh1fM25Ck+NmZAluA3B52eXbIDPXz8yVavbPlgeaSNLsNvVBIf/5z3+488476dOnD1tttRWPPfYYAG+88QaTJk1iiSWWqGeZkqSK8R61+c9NwHnAUcDAzGyMiGk7I2L1zHwFeD0iPgH2aWaOj4Hlv+QcxwE3NNn2GtATGEax5HJWdYuIzTLzwXKe5zPz44gYAlwVEZdl5tsR0RrYIDOHf4VzSdIcd8ghhzB69GjatGnDSSedxGKLLcYuu+zC8ccfz/bbb0/btm0ZMGAADQ0NAGy55ZZ88sknTJo0ibvvvpvLL7+cVVdddTpnkSTNbwxq85nM/DQiBgM/AVZuZsihEbEFMJGis3VIM2NuBvYulxhe1+Q+NTLzyYh4qsn8RwKXRsRHfDHEzYzngf0j4mLgU2Dv8pwPRER/4NYypLUDBlEsnZSkyrrmmmu+sK1du3acc845zY6/55575nRJkqR5QIM3L2tBNXz48K7AG+cPHsnosT7NX9LsNeTcWXnukiRpfjNhwgRGjBgBsHKPHj3enNHjvEdNkiRJkirGoCZJkiRJFWNQkyRJkqSKMahJkiRJUsUY1CRJkiSpYgxqkiRJklQxBjVJkiRJqhiDmiRJkiRVjEFNkiRJkirGoCZJkiRJFWNQkyRJkqSKMahJkiRJUsUY1CRJkiSpYgxqkiRJklQxBjVJkiRJqpg29S5Aqrc/9d+a9u3b17sMSfOZiZOm0K5t63qXIUmaR9lRkyRpDjCkSZK+CoOaJEmSJFWMQU2SJEmSKsagJkmSJEkVY1CTJEmSpIoxqEmSJElSxRjUJEmSJKliDGqSJEmSVDEGNUmSJEmqGIOaJEmSJFWMQU2StMCaOGlKvUuQJKlZbepdgFRv+59+F6PH+sOatCAacm7fepcgSVKz7KhJkiRJUsUY1CRJkiSpYgxqkiRJklQxBjVJkiRJqhiDmiRJkiRVjEFNkiRJkirGoCZJkiRJFWNQkyRJkqSKMahJkiRJUsUY1CRJkiSpYgxqkiRJklQxBjVJkiRJqhiDmiRJkiRVjEFNkiRJkiqmTb0LkCSp3gYOHMigQYNoaGhg9dVX57e//S3/+te/OOmkk5gwYQKtW7fm5JNPZr311uOhhx7i3HPPZdKkSbRt25Zf/epXbLzxxvW+BEnSfMagNg+LiJ8DC2fmeV8y5hTghcy8PiK+C7TLzDtr9h8M/Bz4DGgPDM3MoyNiceDAzDxrFmvbAFg9M28oP3+snL8dsDowohz6NHARcERm7jUr55Kkr+Ldd9/lqquu4rbbbmOhhRbisMMO4+9//ztDhw7l4IMP5jvf+Q73338/Z599Nn/5y19YYokluPjii+nSpQuvvPIK++23Hw8++GC9L0OSNJ8xqM3DMvOSGRhzYs2n3wU6AHcCRERP4HCgZ2aOjojWwNrl2MWBY4CZDmoR0QbYANgeuKGsY6NyX1fgyczcoMlhhjRJdTNlyhTGjx9PmzZtGD9+PJ07d6ahoYGxY8cCMGbMGDp37gzAWmutNe241VZbjQkTJjBx4kTatWtXl9olSfMng9o8ICJOADpl5hHl552ABK4AGsoO2CbAhRT3HbYFTsvMayNiIPAkcD9F56xVRGwFXFfO8RHwCUBmTgGeK097EbB4RDwDfJqZm0TEUcAeFN8344FfZOYzZU2NwG+A7YBHgb7AYuXxD2TmoV9yfd8FzsnMDacGOeCPwLbAwhQh7ufARsA4oG9mvlMeeyywS1nT/wEHTN0nSTOiS5cu/PSnP2WLLbagffv2fPvb32bTTTdl2WWXZb/99uPMM8/ks88+47rrrvvCsXfccQdrrbWWIU2SNNv5MJF5w1XAHmWnCuCHwK3A2JoxxwJnl52qdYDbayfIzOeBS4CrMnODzBxA0VmbDPxvRFwTEQdGxCLlIQcDo8uxm0ytIzN7ZmZ34NflfLXGlfsPAU4E7i6PbzGktaAT8M/yPH8GhgEXZeZ6wHDglwAR8SOgG/CtzPwGcBtw7kyeS9IC7qOPPmLYsGEMGzaMBx98kHHjxjF48GCuvfZa+vXrx/3330+/fv3o37//54579dVXOeecczjllFPqVLkkaX5mUJsHZOZbwAvA98tN+wIDmwy7Fzih7L59MzNHz8C8Y4GNgR0pulj7A49EREu/Gu4REQ9ExAjgdxTLG2tdOf2rmSGfZObfy9dPAW9P7dxRBLVVy9c7AFsBT5Wdu4OBrrOpBkkLiIcffpgVVliBJZdckrZt29KrVy+efvppbr75Znr16gVA7969ee6556Yd88477/DLX/6SM888k5VWWqlepUuS5mMGtXnHQGCfiFgX6Ah87s71zDyfIri8D/whIk6bkUkzszEzn8jM3wGbAl+n6Mh9ThnebgQOz8x1KJYltm8y7JOZuqKWTah5PYVimWXt51M7iw0USzw3KP+tk5nfnk01SFpALLfccjz77LOMGzeOxsZGHnnkEbp160bnzp15/PHHAXj00Ufp2rUrAB9//DEHHnggRx11FD169Khj5ZKk+Zn3qM07bgLOA44CBmZmY0RM2xkRq2fmK8DrEfEJsE8zc3wMLF9zzBpAm8yc+gTGoHgq49sUSyIXiYg2mTkZWIji++Xf5diDplPvxxSBck66FTgsIm7OzA8joj2wRmY+O4fPK2k+sv7667PNNtuw00470aZNG9Zcc01+8IMfsOaaa3LGGWcwefJk2rdvP22J41//+lfeeustLrroIi666CIALr/8cjp16lTPy5AkzWcMavOIzPw0IgYDPwFWbmbIoRGxBTCRoiN1SDNjbgb2LpcJXkdxj9r5EdGZoms1BfhRZr4HEBFXA89HxIflw0ROBJ6IiFEU3bUvMww4OiKeBe6fhfvUpisz/xIRSwH3l6G1FfA/gEFN0kw59NBDOfTQz/9vasMNN+Smm276wtiDDjqIgw6a3u+qJEn6ahoaGxvrXYNUF8OHD+8KvHH+4JGMHjul3uVIqoMh5/atdwmSpPnchAkTGDFiBMDKPXr0eHNGj/MeNUmSJEmqGIOaJEmSJFWMQU2SJEmSKsagJkmSJEkVY1CTJEmSpIoxqEmSJElSxRjUJEmSJKliDGqSJEmSVDEGNUmSJEmqGIOaJEmSJFWMQU2SJEmSKsagJkmSJEkVY1CTJEmSpIoxqEmSJElSxRjUJEmSJKli2tS7AKne/tR/a9q3b1/vMiTVwcRJU2jXtnW9y5Ak6QvsqEmSFliGNElSVRnUJEmSJKliDGqSJEmSVDEGNUmSJEmqGIOaJEmSJFWMQU2SJEmSKsagJkmSJEkVY1CTJEmSpIoxqEmSJElSxRjUJGkBNHHSlHqXIEmSvkSbehcg1dv+p9/F6LH+0KoFy5Bz+9a7BEmS9CXsqEmSJElSxRjUJEmSJKliDGqSJEmSVDEGNUmSJEmqGIOaJEmSJFWMQU2SJEmSKsagJkmSJEkVY1CTJEmSpIoxqEmSJElSxRjUJEmSJKliDGqSJEmSVDEGNUmSJEmqGIOaJEmSJFWMQU2SJEmSKqZNvQuQJNXPxx9/zAknnMArr7xCQ0MDZ5xxBv/85z+54YYbWHLJJQE48sgj+c53vsPbb7/N97//fVZeeWUA1l9/fU455ZR6li9J0nxrngxqEfFd4F7guMw8s2bbOZm54XSO7Qr0yszL5mB9JwMdMvPoOTT/4cA1mfneHJq/K/BkZi7VzL6BwFbA+0AH4F3g0sz8y5yopYX6ngE2zsxxc+uc0vzq9NNPZ7PNNuOCCy5g4sSJjB8/nn/+85/su+++7Lfffl8Yv9JKKzF48OA6VCpJ0oJlXl76OBI4IiIWn8njugIHzv5yChExN8Lv4UDnOTHxDNY/IDO7Z+ZqwC+BEyLiyDlRT3MycwNDmvTVjRkzhieeeIJdd90VgHbt2rHYYovVuSpJkgRzsaMWEbsApwPjgEHl60WBtYEBwNSfDk7MzL+Xx+wN/ApoBF4HflbTRfoP8AhwLNCvmfN9H+gPLARMBI7IzEeBi4CVy67Ma8AfgUMzc7uI6Ay8A/wgMwdFxDHA4pl5fET0BC4AvgaMLY95Ymr3CRgIbAlc1qSOdYGrgUMy8/4m++4DngA2BpYDbsjM48p9ywJ/AFYCFgauzcwzIqJ/OfbGiBgP/BC4C+ieme9FxG1AY831PJWZK0REh3K+nuXpr8rMs2rqeAb4FvABcFBNje2Bq4C3gS90CDPzmYg4DLgyIs7LzMaIOBb4cTnkifLaPyk7jWtQfK1XB4ZTfO3PBb4O3JSZvyrPexSwB8X36HjgF5n5TLmvEVi0nPPNsr6tgWUpuqoXNq1T0he9/fbbLLnkkvTr14+XX36Ztddem/79+wPw17/+lVtuuYV11lmH4447jo4dO047pm/fviy66KIcfvjhbLjhly5ikCRJs2iudNQiogtFgOmTmd0pwhrA4sAlwA8zswewPXBpRCweEetQ/BDfKzPXA0ZQBI1apwH7laGm9nzdgF8Dvct59wduKHcfDLxYdmV2BR4EvhURbYHvAY+WHyk/DouIdsDfgBPKWn4N/K3cDtAJeCIzv5GZl9TUsRVwDbBH05BWYyVgc6A7sH9ErFZuvwq4IDO/CfQAekfE1pl5OkVI3bW8hhcploFuWV7DyhRBdOr13FvO92uKr/e6wCbAPhHRu6aOVYBNM/P7NfUvCdwBPJSZR2VmYwvX8BhFh2/pcs4fl+dYF2hdnnuqHsCeQFCEtgFAb2C9sqZp15+ZPcvvl19TfJ+0ZJHM3Bj4LjCgDKWSpmPy5Mm8+OKL7Lnnntxyyy0svPDCXHbZZey5557cfffdDB48mM6dOzNgwAAAOnfuzL333svgwYM57rjjOOqoo/jkk0/qfBWSJM2f5tbSx40oOjuvlp9fXn78BkWwuL3scN1O0T1bFdgCuC0zR5ZjL6W4N2qazHyXIgDWBgGAbYBuwAPlvFcDbcrA+DmZ+SlFCNyonP8U4NtlJ6kn8BBFqJiYmcPKY+6m6NJFOc14/hsEp+oFnA9sU4aplgzKzM8y8yPgJaBbRHyNInRcUNb/OEUXbc0W5hhW1v4tiqD5eM313FOO2Qr4Y2Y2ZubHwLV8/v28JjMn13y+EPBP4KLMvOBL6gdoqHm9FXBdZn5cBrvLmpznjsz8KDOnAM8Bd2XmhMwcCyTF1w2gR0Q8EBEjgN8BG3zJ+a8DyMw3gQ+BFaZTryRgmWWWYZlllmH99dcHYNttt+XFF19kqaWWonXr1rRq1YrddtuN559/HiiWRi6xxBIArLPOOqy00kq88cYbdatfkqT5Wb0fJtIAPJeZmzfdEREbz+AcZwMvUyyjq533H5m5dzPzNhd27qHoPn0L+AXFAzL2AJ7JzPER0cwhnzO2mW7TKxTLOjcEbv2SY8fXvJ5C8TVpRRFYe2bmpOmdvKz/RIrlicMorv975b/fzMDxAE1/LT6RIvTtEBE3lcGqJT2B98qll9M7T9Pr/cL1l53KG4HNM/OpiFgO+L+ZmLPe39fSPGHppZdmmWWW4V//+herrLIKjzzyCN26deO9996jc+fiNti7776b1VYrGt0ffPABHTt2pHXr1vz73//mzTffZMUVV6znJUiSNN+aWx21x4BvlEsSAfYpPz4FrBYRW0wdGBE9I6KBYsne9yNimXLXART3Yv1/9u49TKuy3v/4ewQhD4hKG213wgy/ZJ4KiTQlPKWiOGyineEJU1BrZylSuq1Mf5kUoGRpWWRqSu20toZnwUMGYoRHNL9qwdZK1DykEHIY5/fHWkPjyMAMAs+Ceb+uq2vWutda9/quZ9j7mo/3ve7nDcqRqAnAV5s13wocFBEfbN5vufkK0L1FN9OAY4GnM3NJuX92+ROKkZ4uTXVGxL7AxmV7a+ZRjKqdFxGfXsl5b5KZr1JMyTy9Wf3vbvZZvOEZMvP/KALKMWXN04ARwNLMfKo8bSrFNNG6iOhGEUTf9Hk28zpwXHmv/ymnUr5JROxCMXL47Wb3+XREdCt/j8ev4j4r8jaKsPV0uf+5lZwr6S342te+xmmnncbgwYP54x//yIknnsi4ceMYPHgwgwcPZubMmZxxRvEa8KxZszjssMOor6/n5JNP5uyzz2bLLdu7npMkSWqLdTLykJnPRsSJwI0R8U/gemApxSjJYcC4iJgIdAH+TPEu25yIOB24rVw84s/ACa3c4vvAF5vd74mIOBL4SURsUvY7nWJhi4eALKfUPVa+p3Yv8Hb+FcymAd+inDaYmUvKxVAuLKclLqR4R2zJykaQMvPpiNgPuCUiNsnMy8qpjIMy82+r+NiOAC6IiIfL/VeBz1IsdnIh8NPysxxeTq2cRvGO2TMAEbGIIuw1+X/l59TU388y8+aVFVCOEn4+IsYD15afAcDpEXE8sCnwHHBeZl5RXnNTGd7uKc/9A8W7hG2Wma9ExNeBWRHxAsXomqS14AMf+AC//vWv39A2bty4FZ574IEHcuCBB66LsiRJ6vDqGhtbWx9izYqIbuVIERFxLHBcZu61Tm4urcDs2bN7AXMnXvcMLy9c2cxOacMzZUJ9rUuQJKlDWLx4MXPmzAHYrm/fvvPaet26fJfn5Ij4VHnPFymmMkqSJEmSWlhnQa1cVv7cdXU/SZIkSVpfravFRCRJkiRJbWRQkyRJkqSKMahJkiRJUsUY1CRJkiSpYgxqkiRJklQxBjVJkiRJqhiDmiRJkiRVjEFNkiRJkirGoCZJkiRJFWNQkyRJkqSKMahJkiRJUsUY1CRJkiSpYgxqkiRJklQxnWtdgFRrk848gK5du9a6DGmdWrK0gS4bd6p1GZIkqRWOqElSB2RIkySp2gxqkiRJklQxBjVJkiRJqhiDmiRJkiRVjEFNkiRJkirGoCZJkiRJFWNQkyRJkqSKMahJkiRJUsUY1CRJkiSpYgxqkiRJklQxBjVJWg1LljbUugRJkrQB61zrAqRaO/7c23h5oX90q32mTKivdQmSJGkD5oiaJEmSJFWMQU2SJEmSKsagJkmSJEkVY1CTJEmSpIoxqEmSJElSxRjUJEmSJKliDGqSJEmSVDEGNUmSJEmqGIOaJEmSJFWMQU2SJEmSKsagJkmSJEkVY1CTJEmSpIoxqEmSJElSxRjUJEmSJKliDGqS9BY1NDQwZMgQTjjhBAAee+wxPv3pTzN48GBOPPFEFixYAMD06dMZOnQogwcPZujQodxzzz21LFuSJFWYQW0diYiBEdEYEV9p0faHNlzbKyJGreX6vhER49fmPdqrrKlLreuQVuWKK65g++23X75/5plnMnr0aKZMmcL+++/PpEmTANhqq634wQ9+wJQpUxg7dixf/vKXa1WyJEmqOIPauvUMcEpEbNnO63oBay2oRUTntdX3W3QWsMKgVuGa1cHMnz+fO++8k2HDhi1vmzdvHv369QPgYx/7GLfeeisAO+64I9tssw0AvXv3ZvHixSxZsmTdFy1JkirPP3ZXIiI+CZwLLAKuLre7AR8ExgJblKd+PTNvKK85GhgDNAJ/Ak7IzOfK8/4G3AN8BThjBfcbBJwJvA1YApySmTOBi4DtIuIB4Engx8DJmXlIRPQE5gOfzsyrI+LLwJaZ+d8R0Q+4ENgMWFheMysiegF/AC4D9gV+1KKOnYGrgC9k5l0tjr2z7LN32fTzzDwvIrYBfghsD9QB4zLzivKaRqBbZi5ouV9unwn8B9ADGJOZv4qIi8r+Z0TE68BAYCKwDAigW0RcBfTKzM+X/W4DPARsl5n/bPn5SmvDt771LcaMGcPChQuXt/Xu3Ztp06ax//77c/PNN/PMM8+86bpbbrmFHXfckS5dHDSWJElv5ohaK8o/+n8EDM7MD1GENYAtKQLJ8MzsCxwKXBIRW0bEThQB7hOZuQswB/hei66/CRwXEe9ocb/tga8BB5f9Hg/8sjz8eeDRzNwtM4cBdwMfjYiNgf2AmeVPyp/TyimDvwK+WtbyNeBXzaYS9gBmZeaHM/OHzerYH5gMHN4ypJWuBGZm5i5lvz8u2y8E5pRtnwDGlp9HW7ySmf2Ao8p+aApfwJ7lc79c7u8GHJSZuwE/AT4ZEZuXx0YBkw1pWlfuuOMOtt56a3ba6Y3/1M8991wmT57M0KFDWbhw4ZvC2BNPPMH48eM555xz1mW5kiRpPWJQa11/4L7MfKLcv7T8+WFgO+CmcoTrJorRs/cD+wA3ZmbTfz6/BNi/eaeZ+SxFAPxai/sdSDEa9duy36uAzmVgfIMyiMwpa9wfOAf4WER0BfoB0ylGnZZk5rTymqkUo3RRdvMa/wqCTT5BMWp1YGY+2vK+ZSDaE7igWS1/Lzf3L5+X8vlvLD+PtvhF+XMm8O8R8baVnHtNZi4s7/Mi8BvgqHIq5Ejg4jbeU3rL7rvvPm6//Xb23XdfTj31VGbOnMlpp53G9ttvz6WXXsqvf/1rDjnkEN797ncvv2b+/Pn813/9F9/+9rd5z3veU8PqJUlSlTn1sf3qgIcyc0DLAxGxRxv7GAc8Bsxu0e/NmXn0Cvr9wAr6uJ1i9OyjwEnAs8DhwAOZ+VpErOCSN1iYmY0t2h6nmNa5O0UAWlMaKP+jQCsh7DWAzGwo617Zv8sFLfa/RxFqnwP+2CxYS2vd6NGjGT16NAD33nsvl156KePHj+eFF16gR48evP766/zgBz/g8MMPB+CVV15h1KhRjB49mr59+9aydEmSVHGOqLXuXuDD5ZREgGPKn/cBvSNi+WhRRPSLiDrgDmBQRGxbHhoJ3Nay48z8BzAB+Gqz5luBgyLig837LTdfAbq36GYacCzwdGYuKffPLn8CJNClqc6I2BfYuGxvzTyKUbXzIuLTK6h7ATADOKVZjW8vN6eWz0v5/IMowiQU79U1Pcvwldy/pVd583O3rOlh4AWKkcCLVnautK5cf/31HHjggRx88MH07NmTT37ykwBceeWVPPXUU1x00UXU19dTX1/PCy+8UONqJUlSFTmi1orMfDYiTgRujIh/AtcDS4G/AocB4yJiIsWqhH+meJdtTkScDtxWLpLxZ+CEVm7xfeCLze73REQcCfwkIuFb3fYAACAASURBVDYp+50OzKJYICMjYg7wWPme2r3A2/lXMJsGfIsyHGXmknIxlAsjomkxkWFl+8qe++mI2A+4JSI2yczLyqmYgzLzb8CRwEURcQzFSNlk4NvAyRTv6j1EMTp4emY+UnZ7annsH7x5uuXKTABuj4hFFIuJtGZS+ezXt6NvaY3q378//fv3B+CYY47hmGOOedM5n/vc5/jc5z63rkuTJEnrobrGxpaz39QkIrpl5qvl9rHAcZm5V43LUgsRMQnIzBzXnutmz57dC5g78bpneHlhw1qpTRuuKRPqa12CJElaDyxevJg5c+YAbNe3b995bb3OEbWVOzkiPkXxOb1IObVP1RAR/04x3XQ+xYieJEmStEEwqK1EZp5L8d1pqqByKuYqV02RJEmS1jcuJiJJkiRJFWNQkyRJkqSKMahJkiRJUsUY1CRJkiSpYgxqkiRJklQxBjVJkiRJqhiDmiRJkiRVjEFNkiRJkirGoCZJkiRJFWNQkyRJkqSKMahJkiRJUsUY1CRJkiSpYgxqkiRJklQxnWtdgFRrk848gK5du9a6DK1nlixtoMvGnWpdhiRJ2kA5oiZJq8GQJkmS1iaDmiRJkiRVjEFNkiRJkirGoCZJkiRJFWNQkyRJkqSKMahJkiRJUsUY1CRJkiSpYgxqkiRJklQxBjVJkiRJqhiDmiQBS5Y21LoESZKk5TrXugCp1o4/9zZeXugf6R3dlAn1tS5BkiRpOUfUJEmSJKliDGqSJEmSVDEGNUmSJEmqGIOaJEmSJFWMQU2SJEmSKsagJkmSJEkVY1CTJEmSpIoxqEmSJElSxRjUJEmSJKliDGqSJEmSVDEGNUmSJEmqGIOaJEmSJFWMQU2SJEmSKsagJkmSJEkVY1CTpBYaGhoYMmQIJ5xwAgDf+9732Hvvvamvr6e+vp677rpr+bmXXHIJBxxwAAceeCB33313rUqWJEkbmM61LkAdR0QMBMZn5u5tOHcecGhmzlnLZUlvcsUVV7D99tuzYMGC5W0jRozguOOOe8N5Tz75JDfccAM33HADzz77LMceeyy33HILnTp1WtclS5KkDYwjapLUzPz587nzzjsZNmzYKs+dNm0ahxxyCF26dOHd7343733ve3nooYfWQZWSJGlD54ia3iQiTgB2yczPR8RHgHuBj2TmrIi4GHgAeBAYC2xRXvb1zLyhvH4QcCbwNmAJcEpmzmxxjy2BXwNTMvOCiNgbuLg8fBdQ1+zc8cDHgS7A34HPZub/RcRFwLzMHFee9yHgF0CfzGxcs5+KOopvfetbjBkzhoULF76h/corr+Taa69lp5124vTTT6d79+48++yz7LrrrsvP2WabbXj22WfXdcmSJGkD5IiaVmQasF+5vR9wT4v92cAPgeGZ2Rc4FLgkIraMiO2BrwEHl8eOB37ZvPOIeG95j4vLkNaVImB9ITN3Bn4LvKfZJWMzs19m7gr8HPh22f594ISIaAp1/1X2aUjTarnjjjvYeuut2Wmnnd7Q/pnPfIapU6dy3XXX0bNnT8aOHVujCiVJUkdhUNObZOaTwCYR8S6KYPbfwH4R8W6gK7ANsB1wU0Q8ANwENALvBw4Etgd+Wx67CugcEduU3b8DuAP4YmZeU7YF8M/MvLO8/y+BfzQr6eCImBkRc4DTgN3K8/4I/Bk4KCK2Ag4DLlvDH4c6kPvuu4/bb7+dfffdl1NPPZWZM2dy2mmn8fa3v51OnTqx0UYb8alPfYqHH34YKEbQ5s+fv/z6Z599lm222aa17iVJktrMqY9qze0UI2XbZOadEfF94JCyvQ54KDMHtLwoIvoDN2fm0Ss49gHgJeBpYBDwu5Xcv7G85r3ABUC/zJwbEXsCk5uddyHwOWBH4NeZ+Y839SS10ejRoxk9ejQA9957L5deeinjx4/nueeeo2fPngBMnTqV3r17A7DvvvsyevRojj32WJ599lnmzZvHLrvsUrP6JUnShsMRNbVmGnA6ML3cn17uTwNmAL0jYp+mkyOiXzkF8VaKEa4PNj/WrN/XgHpgx4j4bnlNUozg7V2ePwzYsjx/C4r33OZHxEbAiS3qvJFiRO5U4KK3/NTSCowbN47BgwczePBgZs6cyRlnnAFA7969Ofjggxk0aBDHH388X//6113xUZIkrRGOqKk1twNN75JR/hwF3J6ZL0XEYcC4iJhIscjHn4HBmflERBwJ/CQiNimPTQdmNXWcmUvKMHYl8CPgBOAzwMUR0UjxjtpT5bkPR8TVwKMUC4ncCAxo1tfrEXE5xTtxLrenNaZ///70798fKIJaa0466SROOumkdVWWJEnqIOoaG113Qeu3iLgN+FFmXt2e62bPnt0LmDvxumd4eWHDWqlN648pE+prXYIkSdoALV68mDlz5gBs17dv33ltvc4RNa23ImJ34H+A+4Ff1bgcSZIkaY0xqGm9lZl/oFhhUpIkSdqguJiIJEmSJFWMQU2SJEmSKsagJkmSJEkVY1CTJEmSpIoxqEmSJElSxRjUJEmSJKliDGqSJEmSVDEGNUmSJEmqGIOaJEmSJFWMQU2SJEmSKsagJkmSJEkVY1CTJEmSpIoxqEmSJElSxXSudQFSrU068wC6du1a6zJUY0uWNtBl4061LkOSJAlwRE2SAAxpkiSpUgxqkiRJklQxBjVJkiRJqhiDmiRJkiRVjEFNkiRJkirGoCZJkiRJFWNQkyRJkqSKMahJkiRJUsUY1CRJkiSpYgxqkiRJklQxBjVJa92SpQ21LkGSJGm90rnWBUi1dvy5t/HyQoPE2jRlQn2tS5AkSVqvOKImSZIkSRVjUJMkSZKkijGoSZIkSVLFGNQkSZIkqWIMapIkSZJUMQY1SZIkSaoYg5okSZIkVYxBTZIkSZIqxqAmSZIkSRVjUJMkSZKkijGoSZIkSVLFGNQkSZIkqWIMapIkSZJUMQY1SZIkSaoYg5qkdWbx4sUMGzaMww47jEMOOYQLL7wQgJtuuolDDjmEPn368PDDDy8//6WXXuKoo47iQx/6EOecc06typYkSVrnOte6gKqLiG8A38rMJatx7TeBYcDzmbl3833gFOCUzDxiFX18CvhvoA54G3BfZg5vby1SFXTp0oXLL7+czTbbjKVLlzJ8+HAGDBjADjvswPe+9z3OOuusN5zftWtXvvjFL/LEE0/wxBNP1KhqSZKkdc+gtmpnAeOBNwS1iOicmctWce1o4D2Z+Xwr+6sKae8ALgY+nJlPR0QdsFt7H2AV9+iUmQ1rss81qY2fs9YTdXV1bLbZZgAsW7aMZcuWUVdXx/bbb7/C8zfddFN23313nnrqqXVZpiRJUs0Z1FYiIi4qN2dExOvAPODvQADdgN0i4qpyvyvwJPDZzHwpIu6mGAGbFhG3AB9tsX8DMD4zdy/vdSjwDWBj4HXgGKATsBR4ASAzG4H7m9V3EHBeed7zwAmZ+WREjAAOzcxh5XnL98vtI4FXgd7AkRHxPHBhuQ/w88w8LyK2AM4HdilrvwM4tWWwi4g9ge9TTKXdGPhmZv48IrYBfghsTzEiOC4zryivaQS6ZeaClvvl9tnAIcDNwNci4gxgePnZLAT2yszXI+IY4HMU/5b/AZyUmdn6b1W11tDQwNChQ3nqqacYPnw4u+66a61LkiRJqhzfUVuJzPx8ublnZu4GvEwxonVQuQ/wxczcPTN3Bh4BvlJeu3eza8e03G9+n4jYAZgEfCYzd6UIdXOBB4HfA09FxDUR8aWI6FFe0xP4GXBEZu4CTAauauOjfRQ4LTN3yswHgCuBmZm5S9nXj8vzzgfuysyPlM/dE/jsCvr7CkUI2w3YCbipbL8QmFP2+QlgbETs1MYaF2Vmv8z8WhnGDqP47HYFBpchbW/gP4EBmdkXGAdc2sb+VSOdOnXiuuuu46677uKhhx7i8ccfr3VJkiRJleOIWvtdk5kLm+0fHRFHAF2AzYDV+avzAODGzHwCIDMXA4vLY0PKcPNxYAgwJiJ2BvoDD2bmo+V5PwUujohubbjf7zLzTwARsTmwZ1kD5f3/Xm4eBnwkIkaX+5sCf1lBf3cAX42I7YHbMvPesn1/iumeZOYzEXEjsA8wpw01Xt5s+1DgB5n5atnXC2X7YGBX4N6IgGLUbqs29K0K2GKLLejfvz933303O+ywQ63LkSRJqhSDWvstaNooR3ROohjpeT4ihgOj1vQNM3MORbi5KCIeBQZSTIlszTLeOFr6thbHF9A2dcCQzPzzKuqbGBFTKILZ9yLi1sz86ir6bmiqMSJa1tfWGuuASzPz6204VxXw4osv0rlzZ7bYYgtee+01ZsyYwciRI2tdliRJUuWs9tTHiNgkIrquyWIq6lWgeyvHtqR4L+qF8rNY0bTAtrgVGBQRvQEiomtEdIuId0bEHk0nRcS7gH+jmBY5E9g1IvqUh48B7i9HnZ4Edin76UKx0uQKle+IzaBYhbLpPm8vN38DnB4RnZraI2K7ln1ExA6Z+afMvAT4LvCR8tBUYGR5zrbAIOD28tiTQL9ye1WrWF4PnNQ0Wtg0/ROYQjGi+a6yvVNE9F1FX6qh5557jqOPPprBgwczbNgw9txzT/bZZx9uu+02BgwYwP33388JJ5zAcccdt/yafffdl7Fjx/K///u/DBgwgCeffLKGTyBJkrRutHlELSLGA7/MzN9HxCHANUBjRHw6M6estQprbwJwe0QsolhMpLmbKRbmeJxikZHf8q+Q0maZ+UREjAT+pwxFDRTB6xXg7Ih4L7CIIlh/NTPvB4iIo4DJEdGZYjGRI8v+ZkbEVIp35v5G8a7bO1ZSwpEUo3XHlPeeDHwb+BLwHeDBcoGPxWXb3Ig4B/hbZv4QODki9qFYGXMx8IWy35OBSyLiIYrRr9Mz85Hy2KnlsX8Av1zFR3QF8E5gZkQsBRZExIDM/G1EnAn8pvzcugBXA7NX0Z9qpE+fPlx77bVvaj/ggAM44IADVnAF3H777StslyRJ2pDVNTY2tunEiHgG2D4z/xkR91L8Af8P4IJyIQ1pvTJ79uxewNyJ1z3Dywsr+w0FG4QpE+prXYIkSVJNLF68mDlz5gBs17dv33ltva4976htWoa0HsD7MvNXAOVojyRJkiRpDWlPUHu8XN3w/cBtsPxdpkVrozBJkiRJ6qjaE9Q+R7FQxFL+tWjGgRQLYUiSJEmS1pA2B7XMnEXxfVvN266i7V+yLEmSJElqg3Z9j1pEHAAcDvTMzMERsTuwRWa6LJskSZIkrSFt/h61iPgC8APgCWBA2bwI+OZaqEuSJEmSOqz2fOH1l4D9M3Ms8HrZ9hgQa7wqSZIkSerA2hPUugFPl9tNX762McWXHEuSJEmS1pD2BLXfAqe3aDsZuGPNlSNJkiRJas9iIl8ApkTESKBbRCTwKnDoWqlMkiRJkjqo9gS1Z4F+5f/eSzEN8veZ+fpKr5IkSZIktUubglpEdAIWAFtm5u+B36/VqiRJkiSpA2vTO2qZ2QA8DvRYu+VIkiRJktoz9fEq4PqI+C7wF/618iN+4bUkSZIkrTntCWonlT+/0aK9EXjfGqlGkiRJktT2oJaZ263NQqRamXTmAXTt2rXWZWzQlixtoMvGnWpdhiRJ0nqjPd+jJkmrxZAmSZLUPm0eUYuIp2n2XlpzmfmeNVaRJEmSJHVw7XlH7cgW++8Avgj8Ys2VI0mSJElqzztqd7Vsi4g7gZuB767BmiRJkiSpQ3ur76gtBlxkRJIkSZLWoPa8o3ZOi6ZNgUHATWu0IkmSJEnq4Nrzjtq7W+wvBM4HfrbmypEkSZIktSeonZGZ81s2RsS2wJvaJUmSJEmrpz3vqD3eSvuja6IQSZIkSVKhPUGtrmVDRGwBvL7mypG0oVmytKHWJUiSJK13Vjn1sdkXXW8SEU+1ONwD+PnaKExaV44/9zZeXmiYWFumTKivdQmSJEnrnba8o3YkxWjajcBRzdobgWczM9dGYZIkSZLUUa0yqDV90XVEvD0z/7n2S5IkSZKkjq3Nqz5m5j8jYjdgb+DtNHtnLTO/vhZqkyRJkqQOqc2LiUTEKGA6sC/wFWBnYDTw/rVTmiRJkiR1TO1Z9fHLwEGZ+R/AovLnMGDpWqlMkiRJkjqo9gS1npl5d7n9ekRslJk3AYPXQl2SJEmS1GG1J6j9JSJ6lduPA/URsTewZI1XJUmSJEkdWJsXEwG+A3wAmAecA1wDdAFOXvNlSZIkSVLH1Z5VHy9rtn1TRGwFdMnMBWujMEmSJEnqqNoz9ZGI6BERR0XElzNzCbBFRLxrLdUmSZIkSR1Se5bn/ziQwBHA18rm3sAP1kJdkiRJktRhtWdEbSLw6cw8CFhWtt0LfGSNVyVJkiRJHVh7glqvzJxWbjeWP5fQvgVJJEmSJEmr0J6g9mhEHNiibX/g4TVYjyRJkiR1eO0ZDRsNXB8RNwCbRMQlFF92Xb9WKpO0wVi8eDFHHHEES5YsoaGhgQMPPJCTTz6Zl19+mVNOOYW//vWvvPOd72TixIl0794dgMcee4yzzjqLBQsWsNFGG3HNNdfQtWvXGj+JJEnSurHKoBYR22bm/MycGRG7AEcClwJPAx/JzL+s7SLbKyIagW6r89UBEXEO8Ehm/s+ar2zdiogtgVGZ+Z1mbZOAyzPz7rfQ73uBi4F3A3XAYmBEZs5Zjb52A3bIzF+ubj2qvi5dunD55Zez2WabsXTpUoYPH86AAQO49dZb2WOPPRg1ahQ/+tGP+NGPfsSYMWNYtmwZY8aMYdy4cfTp04eXXnqJzp2dZS1JkjqOtvzl8ziwBUBm/i0iPpqZQ9duWbWTmV+vdQ1tFREbAY2Z2djKKVsCX6b4snIAMvP4NXDri4GbMvP7ZR3vBJauZl+7AYcCBrUNWF1dHZttthkAy5YtY9myZdTV1TFt2jR+9rOfATBkyBCOOuooxowZw/Tp04kI+vTpA8BWW21Vs9olSZJqoS1Bra7F/sC1UMdbEhFDgW8BrwG/atbeHxhLGTSBr2fmDeWo0sOZ+d3yvJ2A3wDbAz8F/pCZ34+ILmW/BwENwJ8z8z/Ka74CfJLiM/wrMDIz56+gtqOBMRQLsPwJOCEzn4uIERRfdbAIeD8wHzgqM/+6sv4j4hvAB4HuwHuAPSLiTODjQBfg78BnM/P/gIuALSPiAeCfmblnRNwJjM/M6yPisvIz24FidOwe4JjMbCzD1xXAtmXddcAtZTh7V1kTAM1q/ndgNrBdZr5Wtv0G+AUwFZgMbFNeNhX4JnAOxffxPQD8NjNPXsnvrRfwB+DH5e9kk/IzPBHoX36W9Sv6Paj2GhoaGDp0KE899RTDhw9n11135YUXXqBnz54A/Nu//RsvvPACAHPnzqWuro7jjjuOF198kUGDBjFy5Mhali9JkrROtWUxkdZGayohIrah+MO9PjN3o5iGB8Vo0g+B4ZnZl2LU5pJyOuBlwDHNujkWuGwFI1NnAO8DPpyZuwIjy3seSRHqPpqZHwZuBCasoLadKALHJzJzF2AO8L1mp+wFjMnMHYG7gKbguKr++5fP1SczXwLGZma/ssafA98uz/s88HJm7paZe7byEe4EDKIIf30pFogBuBC4IzM/CHyBIgg2+Q5wRUTcFRHfjoh+UIy4ls/x6fI5egG7A9dQBKo/ZebOmbkzcE5mvgB8HZha1nhy+ftp7fcG0AP4XWZ+CPgJMA24qPx8ZwP/1cpzqsY6derEddddx1133cVDDz3E448//objdXV11NUV/12ooaGB2bNnM27cOCZPnszUqVO55557alG2JElSTbRlRK1zROzDv0bWWu6TmbevjeLaqD9wX2Zmuf8jiqDyYWA74KaIaDq3EXh/Zv4uIrpFxM7AH4HPAHusoO9DgdGZuQQgM/9eth9GEUDuK/vuDPxjBdfvA9yYmc+U+5cADzY7/rtmdU/iXytorqr/G5vVAnBwRHwe2Jz2f13Ctc1Gv+6jCIi3lbWfDJCZ/xcRTV/NQGZeFRE3A/sBA4A7ImJkZv6cIuBdAFxOMdJ1aWYuiYiZwCkRMY4izN3SSj170srvjWK0cEFm3lC23wf8JTMfKPdnAwe08/m1jm2xxRb079+fu+++mx49evDcc8/Rs2dPnnvuObbeemsAtt12W/r167d8f8CAATzyyCPssceK/s9UkiRpw9OWP+qfo1g8pMkLLfYbKUadqqYOeCgzB7Ry/HJgBHAn8MdyqmB7+v5mZl66yjNXz6r6X75ISrmwxwVAv8ycGxF7UkwxbKvXmm030MagV46G/RL4ZUQ8TRF2f56ZMyKiU0R8jOLzbRptuyciPkQRpI4CTqcYUWyp1d9bOUK3uFlTw+rWr3XrxRdfpHPnzmyxxRa89tprzJgxg5EjR7Lvvvty7bXXMmrUKK699lr2228/APbaay8mTZrEokWL2HjjjZk1axYjRoyo7UNIkiStQ6uc+piZvTJzu5X8r9YhbSbwoYjoXe43LZZxH9C7HP0DICL6RUTTSOAVFOHieIr30lbkeuBL5btqRMTby/bfAJ+LiK3K9q4RsesKrr8DGBQR25b7IylGq5p8rFndxwJNI5Nt7R+K97iWAPPLxUVObHbsFWDTiFid8HIn5fTQiHg3sG/TgYg4JCLeVm53AnYB5ja79nsU76XNyMyny/O2A17JzF8ApwJ9y3pfoXjfrskMVv5703roueee4+ijj2bw4MEMGzaMPffck3322YdRo0Yxffp0PvGJTzBjxgxGjRoFQPfu3RkxYgTDhg1jyJAh7LjjjgwcOLC2DyFJkrQOrfejD+XCHKOAKRGxiH8tJvISxRTCcRExkWKhjT9TfPdbY2Y+FRGPUiyO8plWuh8LnAc8EBFLgCeBYZn5szK03VVOz9uIYiXEByPiMOCwzDw+M+dExOnAbeVXBvwZOKFZ/9OB8WVYm08x0sTK+l/B8z8cEVcDj1JMDbyRYjoimfliRFwFPBwRL63kPbUV+SLFe2hHUISw3/Ov6ZcDy7qXUvwb+gPFu2ZNfkGxkMnFzdoGAqdGREP5PCdm5uvllMrTIuJB4K7yPbXWfm9aT/Xp04drr732Te1bbbUVl19++Qqvqa+vp77er2mUJEkdU11jY6XXCtlglas+HpqZw2pdy4pExCbA0sxcFhHvAGYB+zV7p25l1+5FsSDIziv56oCamz17di9g7sTrnuHlhQ21LmeDNWWCYUuSJHVcixcvZs6cOQDb9e3bd15br1vvR9S01vSmGFGrAzYGzm5jSPsJxXtoR1c5pEmSJElVZlCrkcy8jOJrAiopMx+i+DLq9l533FooR5IkSepQ2vI9apIkSZKkdcigJkmSJEkVY1CTJEmSpIoxqEmSJElSxRjUJEmSJKliDGqSJEmSVDEGNUmSJEmqGIOaJEmSJFWMQU2SJEmSKsagJkmSJEkVY1CTJEmSpIoxqEmSJElSxRjUJEmSJKliOte6AKnWJp15AF27dq11GRusJUsb6LJxp1qXIUmStF5xRE3SWmVIkyRJaj+DmiRJkiRVjEFNkiRJkirGoCZJkiRJFWNQkyRJkqSKMahJkiRJUsUY1CRJkiSpYgxqkiRJklQxBjVJkiRJqhiDmiRJkiRVjEFN2kAsWdpQ6xIkSZK0hnSudQFSrR1/7m28vHD9DzlTJtTXugRJkiStIY6oSZIkSVLFGNQkSZIkqWIMapIkSZJUMQY1SZIkSaoYg5okSZIkVYxBTZIkSZIqxqAmSZIkSRVjUJMkSZKkijGoSZIkSVLFGNQkSZIkqWIMapIkSZJUMQY1SZIkSaoYg5okSZIkVYxBTZIkSZIqpnOtC5C0Zp1xxhnceeed9OjRg+uvvx6AL33pS8ydOxeAV199lW7dunHdddcB8Nhjj3HWWWexYMECNtpoI6655hq6du1as/olSZJkUKuZiJgHHJqZc2pcx0BgfGbuXu53A74JHAIsAhqB+4EzM/Mv66imw4C9M3PMurjfhmbo0KEceeSRfOUrX1neNnHixOXbY8eOZfPNNwdg2bJljBkzhnHjxtGnTx9eeuklOnf2/y1IkiTVmlMftVxE1AE3ABsDO2XmzsCHgKlArxWcv1b+os/M3xjSVl+/fv3o3r37Co81NjZy0003ceihhwIwffp0IoI+ffoAsNVWW9GpU6d1VqskSZJWzP90vg5ExB7AOKBb2dQUQv4zIn4MvINiVOv75fnjgY8DXYC/A5/NzP+LiF7AH4BLgEHApsBxmfm7lR0r+xwEnAm8DVgCnJKZM1uUuh9FINsvM5cCZGYD8LNmz3IZsAyI8nl2i4iDgPOATsDzwAmZ+WREjKAYNRxWXrt8v9w+gmLU7v3AfOCozPxri/MGAhOBe4E9KEb4Ds/MP5Z9ngt8GngBuLOsffdV/Eo6rD/84Q/06NGDXr16ATB37lzq6uo47rjjePHFFxk0aBAjR46sbZGSJElyRG1ti4itgf8FvpyZuwIfBmaVhzfNzD2AgcDYiNi8bB+bmf3K838OfLtZlz2AezLzQ8A5bTkWEdsDXwMOzsy+wPHAL1dQ7oeB+5pC2krsBhyUmbtFRE+KIHdEZu4CTAauWsX1TfYCxmTmjsBdwHdbOe+DwA/L/n8JfLV8rsHAocCuFCGudxvv22Fdf/31y0fTABoaGpg9ezbjxo1j8uTJTJ06lXvuuaeGFUqSJAkMauvCHsCjmTkDihGqzHypPPaLsm0e8BLwrrL94IiYGRFzgNMoglGTBZl5fbk9E9i+DccOLLd/GxEPUASpzhGxzcoKj4j9I+KBiPhTRJzW7NA1mbmw3O4PPJiZj5b7P6UYZevGqv0uM7PcngTs28p5mZn3r+C59gF+mZkLM/N14PI23LPDWrZsGbfddhuDBg1a3rbtttvSr18/tt56azbZZBMGDBjAI488UsMqJUmSBAa1Wnut2XYDRXh6L3AB8JnM3An4LMV0xSaLW17ThmN1wM2ZuVuz//17Zj7bTZfEVgAAIABJREFUop77gQ81vXuWmVMzczeKEcHNm523oI3Pt4w3/ht7W2snrsKbPqfV7KdDmzFjBu973/vYdtttl7fttddePP744yxatIhly5Yxa9Ys3v/+99ewSkmSJIFBbV24B9ixfE+NiOgUEVut5PwtKN4hmx8RGwEnroEabgUOiogPNjVERL8VnDcV+AtwQUQ0D1WbrqTvmcCuEdGn3D8GuD8zXwWeBHaJiK4R0QUY1uLaj0VE03TFY4Hb2/xEhTuBYRGxaflZHdXO6zdIp556Kocffjhz585lwIABXH311QDceOONHHLIIW84t3v37owYMYJhw4YxZMgQdtxxRwYOHFiDqiVJktScIxNrWWa+GBFDgfMjYjPgdYrpjK2d/3BEXA08SrGQyI3AgLdYwxMRcSTwk4jYhGKRkun86125pvMaI+Jg4FzgkYhYCLwKJHBlK30/HxFHAZPLkbjngSPLYzMjYirwCPA34EGKhVOaTAfGl2FtPu0MWpn5m4jYE3gIeJEiNK4sBHcI559//grbx44du8L2+vp66uvr12ZJkiRJaqe6xsbGWtegDqjlipBvoZ9umflqOaI2CfhbZn61LdfOnj27FzB34nXP8PLChrdSRiVMmWDYkiRJqprFixczZ84cgO369u07r63XOaKm9d0V5VcTbALMBr5T23IkSZKkt86gpprIzMuAy9ZAP//xlouRJEmSKsbFRCRJkiSpYgxqkiRJklQxBjVJkiRJqhiDmiRJkiRVjEFNkiRJkirGoCZJkiRJFWNQkyRJkqSKMahJkiRJUsUY1CRJkiSpYgxqkiRJklQxBjVJkiRJqhiDmiRJkiRVjEFNkiRJkiqmc60LkGpt0pkH0LVr11qX8ZYtWdpAl4071boMSZIkrQGOqEkbCEOaJEnShsOgJkmSJEkVY1CTJEmSpIoxqEmSJElSxRjUJEmSJKliDGqSJEmSVDEGNUmSJEmqGIOaJEmSJFWMQU2SJEmSKsagJlXUkqUNtS5BkiRJNdK51gVItXb8ubfx8sLqhaIpE+prXYIkSZJqxBE1SZIkSaoYg5okSZIkVYxBTZIkSZIqxqAmSZIkSRVjUJMkSZKkijGoSZIkSVLFGNQkSZIkqWIMapIkSZJUMQY1SZIkSaoYg5okSZIkVYxBTZIkSZIqxqAmSZIkSRVjUJMkSZKkijGoSZIkSVLFdK51AZJW7owzzuDOO++kR48eXH/99QBMnDiRadOmsdFGG9GjRw/OO+88ttlmGwAee+wxzjrrLBYsWMBGG23ENddcQ9euXWv5CJIkSWqnDj+iFhHfiIguq3ntNyPisYi4u+V+ROweEVe1oY9PRcT9EfFAee3k1allfRQRd0bEoeX2pIjYu9Y1VdHQoUOZNGnSG9qOP/54pkyZwnXXXcfAgQO56KKLAFi2bBljxozh7LPP5oYbbuCKK66gc2f/e4wkSdL6xr/g4CxgPLCkeWNEdM7MZau4djTwnsx8vpX9I1Z2cUS8A7gY+HBmPh0RdcBu7X2AVdyjU2Y2rMk+14bMPL7WNVRVv379+Mtf/vKGts0333z59qJFi6irqwNg+vTpRAR9+vQBYKuttlp3hUqSJGmN6dBBLSIuKjdnRMTrwDzg70AA3YDdylGxALoCTwKfzcyXylG0twHTIuIW4KMt9m8Axmfm7uW9DgW+AWwMvA4cA3QClgIvAGRmI3B/s/oOAs4rz3seOCEzn4yIEcChmTmsPG/5frl9JPAq0Bs4MiKeBy4s9wF+npnnRcQWwPnALmXtdwCntgx2ZZ/DgZfLc/8KfIEi4L4fmAUcmZmNK+szInYEfgpsDjxcHm+6x53l53V98+1Wjs0GPgL0Ar7brJ5/B8Zk5tV0ABdccAHXXnst3bp144orrgBg7ty51NXVcdxxx/Hiiy8yaNAgRo4cWeNKJUmS1F4deupjZn6+3NwzM3ejCCK7AQeV+wBfzMzdM3Nn4BHgK+W1eze7dkzL/eb3iYgdgEnAZzJzV4pQNxd4EPg98FREXBMRX4qIHuU1PYGfAUdk5i7AZGCVUylLHwVOy8ydMvMB4EpgZmbuUvb14/K884G7MvMj5XP3BD7bSp/9KAJXH2BRWc9wYEdgZ2C/NvT5M+DizPwgMLHsc3W8C/g40B84B9gpM/cE/hO4YDX7XO+ccsop3HXXXQwePJgrr7wSgIaGBmbPns24ceOYPHkyU6dO5Z577qlxpZIkSWqvDh3UWnFNZi5stn90RMyOiIcpgsnqTE08ALgxM58AyMzFmflqZr6emUOAgRQjT4cAD0XE1hQh5MHMfLTs46cUI3zd2nC/32XmnwAiYnNgT5oFmMz8e7l5GDAmIh4A7gP6Aju00uf0zGyaf3d/eY+Xy+mhD1KMrLXaZznSthNFWCMzZ1KMqq2Oq8vP7m8Uo5H/W7bPBt4ZEW9r/dINz+DBg7n11lsB2HbbbenXrx9bb701m2yyCQMGDOCRRx6pcYWSJElqrw499bEVC5o2ysUtTqIYJXs+IoYDo9b0DTNzDjAHuCgiHqUIbktXcsky3hiyWwaTBbRNHTAkM//chnNfa7bdsIL9pn9LK+yzDGpttarnW2Et5fRK6AD/rufNm0evXr0AmDZtGu973/sA2GuvvZg0aRKLFi1i4403ZtasWYwYMaJ2hUqSJGm1OKJWvMvVvZVjWwL/AF6IiK60Pi1wVW4FBkVEb4CI6BoR3SLinRGxR9NJEfEu4N8opkXOBHaNiD7l4WOA+zPzVYp35XYp++kCDGvtxpm5AJgBnNLsPm8vN38DnB4RnZraI2K71XzGJivsMzNfoRhBG162f4RiyuSKPEk5LbJ8r22NLrCyvjn11FM5/PDDmTt3LgMGDODqq69mwoQJHHrooQwePJjp06dz5plnAtC9e3dGjBjBsGHDGDJkCDvuuCMDBw6s7QNIkiSp3Tb4kYc2mADcHhGLKBYTae5mioU5HqdYZOS3FItYtEtmPhERI4H/KQNMA0XwegU4OyLeS/He10bAVzPzfoCIOAqYHBGdKRYTObLsb2ZETKV4Z+5vFFMP37GSEo6kGK07prz3ZODbwJeA7wAPRkQjsLhsmxsR5wB/y8wftvNxW+0TOBr4aUScThHaZrXSx3eAqyNiCMX0yftbOa9DOP/889/U9qlPfarV8+vr66mvr1+bJUmSJGktq2tsbKx1DVJNzJ49uxcwd+J1z/Dywup9g8GUCYYtSZKk9d3ixYuZM2cOwHZ9+/ad19brnPooSZIkSRVjUJMkSZKkijGoSZIkSVLFGNQkSZIkqWIMapIkSZJUMQY1SZIkSaoYg5okSZIkVYxBTZIkSZIqxqAmSZIkSRVjUJMkSZKkijGoSZIkSVLFGNQkSZIkqWIMapIkSZJUMQY1SZIkSaoYg5okSZIkVUznWhcg1dqkMw+ga9eutS7jTZYsbaDLxp1qXYYkSZJqwBE1qaIMaZIkSR2XQU2SJEmSKsagJkmSJEkVY1CTJEmSpIoxqEmSJElSxRjUJEmSJKliDGqSJEmSVDEGNUmSJEmqGIOaJEmSJFWMQU2SJEmSKsagJtXIkqUNtS5BkiRJFdW51gVItXb8ubfx8sJ1H5qmTKhf5/eUJEnS+sERNUmSJEmqGIOaJEmSJFWMQU2SJEmSKsagJkmSJEkVY1CTJEmSpIoxqEmSJElSxRjUJEmSJKliDGqSJEmSVDEGNUmSJEmqGIOaJEmSJFWMQU2SJEmSKsagJkmSJEkVY1CTJEmSpIoxqEmSJElSxXSudQFSR/b/2bvzcL3Ge//j751EQgkhJKWcBuXLEWOkoYOatSS0hiJ1DBU6/SjaKkfR9hhyisqh/ExViamHoycJokVUqpQfSQ2p9kuLVo1tipoy2Pbvj3Vvdra9M9p5VrLfr+tyPc+z1rrv+7ueva7n8nHfaznxxBO588476d+/PzfddBMAL7/8MsceeyzPPPMMH/rQhxgzZgyrrLIKEydO5Mc//vE7bTOT//3f/2XjjTduVPmSJEnqIt1yRi0iWiJipUVs+/2I2P/9rqn0PSgi/r6YfVwWEZ9czD52i4i7I+LxiHggIm6KiE3n02ZQRBy5OON2R3vvvTeXXXbZXNsuueQStt12W2699Va23XZbLrnkEgD23HNPJkyYwIQJE/jBD37A2muvbUiTJElaRnXLoLY4MvOUzPzvRtfRmcwclZl3LWr7iNgV+DHw9czcIDO3Br4DrDmfpoOAJRrUIqLnkhyvKwwdOpRVVlllrm2TJ0/ms5/9LACf/exnuf3229/T7uabb2aPPfZYIjVKkiRpyesWSx8jYm/gDGAmcEOb7cOA0cDKZdMpmXlzRFwGPJKZ/1WOGwxMBNYHfgI8kJk/iojepd9PA83AE5n5udLm28A+VN/xM8ARmfl8B7V9DTgW+Cdwc7t9uwMnAcsDs4FjM/PeiLgdOD8zJ5TjhgPfyMwdIuJO4OzMvCkiVgHOBYYCbwN3Zeb/KXWfDnwK6AM8DHwlM18DTgH+IzMfaK0jMx9sU9PVQJR2fwS+mJkvARcA60bEg8AfM3PfiAhgDLA60BsYk5k/Kf3sU2p4E7i+vO+bma9FxKeBM4GewN+AL2XmHyNie+A8YCqwJfDDiPhPYN3MnFn6nQj8NDOvaf9dLy1mzJjBgAEDAFhjjTWYMWPGe46ZNGkSF1544ZIuTZIkSUvIMj+jFhEDgUuBvTJzC2BW2dUPuAgYmZlDgOHAxRHRD7gCOKRNN4cBV2RmS7vuTwTWA7bKzM2BI8qYB1GFum0ycytgEnBOB7VtRhXEPl6O699m3/rAycBnSn2jgOvK7o7q+0kHpz8GeB3YvNT33bL9eOCVzPxo2f5sOReArYD7Ouir1dczc+vM3BT4HfDtsv1rwKOZuUUJab2Aa6jC5VDgE8AJEbFR+ZtcAozIzC2pwlrreQ8ArgS+kJmblT6ubjP+JsAlZZxxwBRg/9J2ELA18D/zqH+p0tTURFNT01zbHnroIVZYYQU23HDDBlUlSZKkrtYdZtSGAdMyM8vnS4D/pAok6wK3VBM/ALQAH8nMX0dE33Jf1u+BA4FtO+i7dSZrNkBmtt5ftidVYJhW+u4FvNJB++2BmzPzhTa1fb68340q7P2qTX29Ssj5GXBuRLQGu08BB3dS35DMfLuD+laOiH3L5z7AQx2078jBEfEFqhmyFYHHOjluQ2Bj4Kdt6u9TtjVT/U0eL9svB35Y3g8DHsrMR8vnnwAXRkTf8vnxzPxNm3HOo5o1HAt8Gbi89e+xtOrfvz8vvvgiAwYM4MUXX2S11Vaba7/LHiVJkpZ93SGodaYJeDgzt+tk/1jgUOBO4PeZ+eeF7Pu0zLx8Mev7eWZ2FMCIiAnAyPJxQma+vpB9fzUz7+hg3zTgo8CD7XeUh5R8BfhYZv4tIkbS+X1pTcDfyyxm+372XIha23ut7YfMvCciekbEx6n+XkMXo+9a2HHHHRk/fjxHHnkk48ePZ6eddnpn39tvv80tt9zCNdcstSs7JUmStACW+aWPwL3AlhGxQfk8qrxOAzaIiB1aD4yIoRHRus5sHNVM2ig6XlYIcBNwTLnni4hYvWyfCHw1IlYt2/tExOYdtL8T2L0s9wM4vM2+W4FPR8Qmbetrs/8KqmBy6Hzq+1brObWr77iIWKFs7xsRrY8PPA04OSK2ajPuZuUhI/2oZgZnREQf4Ittxvon0PapGAm8ERH/1qafjSJiZaqllVuV5Z0w9zLOe4HNI2KjNvt+m5mvdnKOAOcDPwXuycyn53Fc7Rx33HEccMABPPnkk2y33XZcf/31HHnkkdx9993suuuu3HPPPRx55LtZ+P7772fNNddknXXWaWDVkiRJ6mrL/IxaZr5YHht/Y0S8ybsPE3mJagngWRExhmop3xPACKAlM/8SEY9SLU88sJPuR1M99OLBiJhN9XCNfTPzyhKKppRlfz2AC4GHymzSnuXpjA9HxBnA3RHxT6p72Vrrfrzc6/bjEqh6A3cD95f9vy6hh8z8dSf1HUt1n9r0iHiL6n6uo0vd3wXuj4i3qZZ8fo9q5vDnEfEl4IKytHIO8CRwAlX4OohquePfgV9Rzb5B9UCSjIjpwB/KfWojgDER8S2qB4O8AHw+M1+IiC8DkyLiDapAOQd4ozxM5N+Aa8p9bn8rY87LT6keZrLUPV3jhz/8YYfbx44d2+H2YcOGcd1113W4T5IkScuOppaW9s/HkLpeRPRtnSWLiMOAwzPzE4vY1yeoHgyzaQcPfOnU1KlTBwFPjpnwHC+/3rwoQy+WG8/Za4mPKUmSpCVr1qxZTJ8+HWDdIUOGPLWg7Zb5GTXV1tERsR/VNfgPyhMzF1ZE/BjYBTh4YUKaJEmSVGcGNTVEZp5O9f9OW9x+Dp//UZIkSdLSpTs8TESSJEmSlioGNUmSJEmqGYOaJEmSJNWMQU2SJEmSasagJkmSJEk1Y1CTJEmSpJoxqEmSJElSzRjUJEmSJKlmDGqSJEmSVDMGNUmSJEmqGYOaJEmSJNWMQU2SJEmSasagJkmSJEk106vRBUiNdtlJu9CnT58lPu7sOc30Xq7nEh9XkiRJ9eeMmtQghjRJkiR1xqAmSZIkSTVjUJMkSZKkmjGoSZIkSVLNGNQkSZIkqWYMapIkSZJUMwY1SZIkSaoZg5okSZIk1YxBTZIkSZJqxqAmLUGz5zQ3ugRJkiQtBXo1ugCp0Uadfhsvv75kAtSN5+y1RMaRJEnS0s0ZNUmSJEmqGYOaJEmSJNWMQU2SJEmSasagJkmSJEk1Y1CTJEmSpJoxqEmSJElSzRjUJEmSJKlmDGqSJEmSVDMGNUmSJEmqGYOaJEmSJNWMQU2SJEmSasagJkmSJEk1Y1CTJEmSpJoxqEmSJElSzRjUpCVs7NixDB8+nD322IMrrrgCgPPPP59PfvKT7LXXXuy1115MmTKlsUVKkiSpoXo1ugB1LiJagL6Z+doitP0+8LvM/O/3oY5BwAOZufri9tXdPfbYY1x//fVcf/31LLfccowaNYoddtgBgEMPPZTDDz+8wRVKkiSpDpxRW0Zl5invR0hbWBHR8PBfhxo686c//YnNNtuMFVZYgV69ejF06FBuvfXWRpclSZKkmqntv9B2RxGxN3AGMBO4oc32YcBoYOWy6ZTMvDkiLgMeycz/KscNBiYC6wM/oZoF+1FE9C79fhpoBp7IzM+VNt8G9qG6Fp4BjsjM5zup7xxgF6AJ+Gpm3tU62wZcAewIXBIRVwHnA0NL03GZ+YOICOBnmblJCVMzgNMy86yI+Dzw2cwcGRGnAgeW76EF2CEzX57H9/CeGoCLFviLX4I23HBDxowZw0svvcTyyy/Pr371KwYPHky/fv246qqrGD9+PIMHD+aEE05glVVWaXS5kiRJahBn1GoiIgYClwJ7ZeYWwKyyqx9V6BiZmUOA4cDFEdGPKpgc0qabw4ArMrOlXfcnAusBW2Xm5sARZcyDqELdNpm5FTAJOKeTEvsDD2XmZsBRwLUR0afNvvszc6vMvAg4mera2hT4GHBIRHwmMxNYOSLWpApxvwN2Kn3sBEyOiNWAY4Ety/ewHfBaOd/OvoeOaqil9ddfn1GjRnH44YczatQoNtpoI3r06MGBBx7I7bffzoQJExgwYACjR49udKmSJElqIINafQwDppUwA9WsEMBWwLrALRHxIHAL1SzTRzLz10DfiNi0zFAdCIztoO/hwJjMnA2QmX8v2/cEdgamlb6/BgzqpL7ZwFWl/Z3Am0CUfTOB69ocuzNwaWa2ZOY/gWvLNoA7qELZzsDFwDplxm/nsu8V4I/AuIg4AlgpM9+iCnwdfg+d1FBb++23Hz/72c+4+uqrWWWVVRg0aBCrr746PXv2pEePHuy333488sgjjS5TkiRJDeTSx/prAh7OzO062T8WOBS4E/h9Zv55Ifs+LTMvX6wK4fUOZvE60xrU1gUOopoxOxBoyswnASJiG+DjVMsYp0bEp5nH91CWPi5MDQ01Y8YM+vfvz7PPPsutt97Kddddx4svvsiAAQMAuP3229lggw0aXKUkSZIayRm1+rgX2DIiWv8NfVR5nQZsEBE7tB4YEUMjoql8HEcVdEZR3ZfWkZuAY8rMFRHR+vTGicBXI2LVsr1PRGzeSR+9gZHluE8CKwB/6OTY24HDI6IpIvoCBwC3lX2Tgd2AVTPzr+XY75XtlOPXyMwpmXkqMB0YDNwzn+9hqXHUUUex++678+Uvf5lTTz2VlVdembPOOosRI0YwYsQI7r33Xk488cRGlylJkqQGckatJjLzxYg4ErgxIt7k3YeJvES1RPGsiBhDFZieAEYALZn5l4h4FNieKrB1ZDRwJvBgRMymWlq4b2ZeWULblOo5H/QALgQeiog9gT0zszUwzgC2iIjjqWa3DszM2aVde/8B/AhoXb93ZWb+vJznXyPiVeDXZd8dwL+UV4BVgBsiYoVSzzSqB5DMLDV19D0sVa655pr3bDvrrLMaUIkkSZLqqqmlZalYLSa976ZOnToIeHLMhOd4+fXmJTLmjefstUTGkSRJUj3MmjWL6dOnA6w7ZMiQpxa0nUsfJUmSJKlmDGqSJEmSVDMGNUmSJEmqGYOaJEmSJNWMQU2SJEmSasagJkmSJEk1Y1CTJEmSpJoxqEmSJElSzRjUJEmSJKlmDGqSJEmSVDMGNUmSJEmqGYOaJEmSJNWMQU2SJEmSasagJkmSJEk1Y1CTJEmSpJrp1egCpEa77KRd6NOnzxIZa/acZnov13OJjCVJkqSllzNq0hJkSJMkSdKCMKhJkiRJUs0Y1CRJkiSpZgxqkiRJklQzBjVJkiRJqhmDmiRJkiTVjEFNkiRJkmrGoCZJkiRJNWNQkyRJkqSaMahJkiRJUs0Y1KQuNntOc6NLkCRJ0lKmV6MLkBpt1Om38fLrXRembjxnry7rW5IkScsmZ9QkSZIkqWYMapIkSZJUMwY1SZIkSaoZg5okSZIk1YxBTZIkSZJqxqAmSZIkSTVjUJMkSZKkmjGoSZIkSVLNGNQkSZIkqWYMapIkSZJUMwY1SZIkSaoZg5okSZIk1YxBTZIkSZJqxqAmSZIkSTXTq9EFSN3FFVdcwfXXX09TUxMbbrghZ555Jn369OHKK6/k6quvpmfPnnzqU5/i+OOPb3SpkiRJajCD2mKKiO2BXwInZOZ/ttl2dmZuPZ+2g4BdM/OSLqzvu8BKmfnNrhqjk3GPAa7JzBfL5y8DK2TmuV003vZA78y8tSv6X1wvvPAC48aNY9KkSSy//PJ8/etf5+abb2attdZi8uTJTJw4kd69ezNjxoxGlypJkqQacOnj++M54NiI6LeQ7QYBR77/5VQiopFB/BhgQOuHzLyoq0JasT2waxf2v9iam5uZOXMmb731FjNnzmTAgAFce+21HHnkkfTu3RuA/v37N7hKSZIk1UG3nFGLiH2A04E3gevL+77AJsBoYOVy6CmZeXNpczDwLaAF+BPwpdbZIuBZ4DfAt4ETOxhvd+AkYHlgNnBsZt4LXACsGxEPAn8ELgWOzsw9ImIA8Dywf2ZeHxHHA/0y898jYihwHrAi8Hppc3+ZoXsAuALYEbikXR2bAlcDR2XmlHb7PlT63KBsujYzz4yIgcBFwPpAE3BWZo4rbZ4CxgG7AGtSzSL+KCJOAtYC/iciZgIjgc9TZvYi4tCy7SVgMPAysE9mPl/6/TawD9X1+QxwRGY+X2YHA1gFWK/8HfYrtX0Z6BEROwM/zczR7f8OjTRw4EC++MUvssMOO9CnTx8+/vGP84lPfIKzzjqLBx54gHPPPZc+ffpw/PHHs9lmmzW6XEmSJDVYt5tRK8HjEmBEZm5JFdYA+lEFkpGZOQQYDlwcEf0iYjBVgNs1MzcDpgPnt+v6NODwiFiz3XjrAycDnyn9jgKuK7u/BjyamVtk5r7AXcA2EbEcsBNwb3mlvE6OiN7ADcB3Si0nAzeU7QD9gfszc6vMvKhNHTsD1wAHtA9pxVXAvZm5Wen30rL9PGB62bYrMLp8H60+kJnbUs1ojY6IlTLzdKrwum85t0c7GG8o8M3M3AR4FDiq1HkQVfDaJjO3AiYB57RptzVVyNsYWA74QmY+QvW3G1fGq1VIA3jllVeYPHkykydP5q677uLNN99kwoQJNDc388orr3Dddddx/PHHc8wxx9DS0tLociVJktRg3S6oAcOAaZn5ePl8eXndClgXuKXMcN1CNXv2EWAHYFJmPleOvRjYuW2nmfkCVQA8ud14u1EFj1+Vfq8GepXAOJfMfIMqBA4r/X8f+HhE9KEKNndTzSjNzszJpc3tVLN0UbqZybtBsNWuwBhgt45CU0SsBHwMeGdpYmb+vbzduZwv5fwnle+j1U/LvqeoZsjWbt9/J+7OzKfL+3upviOAPcuY08r39TWqJaKtfpGZL2dmC3Bfm3a1ds8997D22muz2mqrsdxyy7Hrrrvy29/+loEDB7LLLrvQ1NTEZpttRo8ePXjppZcaXa4kSZIarFsufexEE/BwZm7XfkdEbLuAfZwF/AGY2q7fn2fmwR30u3EHfdxBNXu2DfAV4AXgAODBzJwZER00mcvrJcS09RjVss6tgYkLcB4LY2ab980s+DXVWbsm4LTMvPy9TTpst8ICjtdQa621Fg899BBvvvkmyy+/PL/5zW8YPHgwEcF9993HNttsw5NPPsmcOXNYddVVG12uJEmSGqw7zqjdB2xVliQCHFJepwEbRMQ7s0URMTQimqie6rh7RHyw7DoCuK19x5n5CtUyve+02Xwr8OmI2KRtv+XtP6nut2prMnAY8HRmzi6fv1deARLo3VpnROxItQQw53HOT1HNqp0ZEft3UPdrwD3AsW1qXL28vb2cL+X8d6cKk/PT0bktiInAVyNi1TJmn4jYvAvHWyI233xzdtttNz73uc8xYsQI3n77bfbff3/22Wcfnn76aYbkcQltAAAgAElEQVQPH85xxx3H6NGjaWpqanS5kiRJarBuN6OWmS+UR8VPiog3gJuAOVQPrdgTOCsixgC9gSeo7mWbHhEnALdFREvZ/qVOhvgR8PU24z1e7rv6cUSsUPq9G7gfeBjIiJgO/KHcp3YfsDrvBrPJwBmUcJSZs8vDUM6LiNaHiexbts/rvJ+OiJ2AX0TECpl5RVlauHtmPgscBFwQEYdQzVRdA/wncDTVvXoPU812nZCZv5v/N815wE/KdzxyAY5vrfPKEhKnlPPpAVwIPDSfpv8LHFzOqXYPEwE4+uijOfroo9+z/eyzz25ANZIkSaqzpu744IKI6JuZr5b3hwGHZ+YnGlyWlrCpU6cOAp4cM+E5Xn69ucvGufGcvbqsb0mSJNXbrFmzmD59OsC6Q4YMeWpB23W7GbXi6IjYj+r8/0FZ2idJkiRJddAtg1p5fPzpja5DkiRJkjrSHR8mIkmSJEm1ZlCTJEmSpJoxqEmSJElSzRjUJEmSJKlmDGqSJEmSVDMGNUmSJEmqGYOaJEmSJNWMQU2SJEmSasagJkmSJEk1Y1CTJEmSpJoxqEmSJElSzRjUJEmSJKlmDGqSJEmSVDO9Gl2A1GiXnbQLffr06bL+Z89ppvdyPbusf0mSJC17nFGTupghTZIkSQvLoCZJkiRJNWNQkyRJkqSaMahJkiRJUs0Y1CRJkiSpZgxqkiRJklQzBjVJkiRJqhmDmiRJkiTVjEFNkiRJkmrGoCYthNlzmhtdgiRJkrqBXo0uQGq0UaffxsuvL1gAu/Gcvbq4GkmSJMkZNUmSJEmqHYOaJEmSJNWMQU2SJEmSasagJkmSJEk1Y1CTJEmSpJoxqEmSJElSzRjUJEmSJKlmDGqSJEmSVDMGNUmSJEmqGYOaJEmSJNWMQU2SJEmSasagJkmSJEk1Y1CTJEmSpJoxqEmSJElSzfRqdAHS0qq5uZl99tmHgQMHcvHFFzNmzBgmT55Mjx496N+/P2eeeSYDBw5sdJmSJElaCnWrGbWI2D4iWiLi2+22PbAAbQdFxJFdXN93I+LsLuh3UET8fR77+0bE+RHxx4h4MCKmRsS/L+aYh0bEhm0+7xkRZy1On/MZb4uI+HxX9d+RcePGsf7667/zedSoUdx4441MmDCB7bffngsuuGBJliNJkqRlSLcKasVzwLER0W8h2w0CuiyoRURDZjcjogmYBDQB/5qZWwAfB15dzK4PBd4Japk5MTO/tZh9zssWwBILas8//zx33nkn++677zvbVlpppXfev/nmmzQ1NS2pciRJkrSMqf3Sx4jYBzgdeBO4vrzvC2wCjAZWLoeekpk3lzYHA98CWoA/AV/KzBfLcc8CvwG+DZzYwXi7AycBywOzgWMz817gAmDdiHgQ+CNwKXB0Zu4REQOA54H9M/P6iDge6JeZ/x4RQ4HzgBWB10ub+yNiEPAAcAWwI3BJuzo2Ba4GjsrMKe32nQocCMws57gD0A94IDNXL8cMavu5bDsH2IUqlH01M+8CdgI+DOyYmXMAMnMmcH5ps1J5P7R0My4zf1D23QncD2wLrAVcl5knRMRhwNbAeRFxGvBNYG1geGbuGxHbA2OA+0rbFuCAzPx96fcQ4KtU1+crwFcyMyPiUGAk8BIwGHgZ2AeYA3wfWLn8fX6VmUe3/9u+n8444wy+9a1v8frrr8+1/dxzz2X8+PH07duXcePGdWUJkiRJWobVekYtIgZSBZgRmbklVViDKpRcBIzMzCHAcODiiOgXEYOpAtyumbkZMJ0SOto4DTg8ItZsN976wMnAZ0q/o4Dryu6vAY9m5haZuS9wF7BNRCxHFXbuLa+U18kR0Ru4AfhOqeVk4IayHaA/cH9mbpWZF7WpY2fgGqrw0j6krQYcC2xZZr+2A15bgK+zP/BQqeMo4NqI6ANsBUxrDWkdOJnqOtkU+BhwSER8ps3+fyk1bAmMiogNMvMnVCH06PJ93d5Bv5sAF5V6rgO+U87vk1QzY9uVv8FZwOVt2g0FvpmZmwCPUgXZGcApwO1lvC4Nab/85S9ZbbXVGDx48Hv2HXvssUyZMoURI0Zw1VVXdWUZkiRJWobVOqgBw6hCxOPlc+u/sG8FrAvcUmZQbqGalfkI1ezSpMx8rhx7MbBz204z8wWqAHhyu/F2A9YHflX6vRroVQLjXDLzDaoQOKz0/33g4yX8DAXuBgKYnZmTS5vbqWbponQzk3eDYKtdqWabdsvMRzv4Tl6hmtEbFxFHACtl5lsdHNfebOCqUsedVKE35tWg2Bm4NDNbMvOfwLXM/X1en5lvZ+YrwO+pvr8FkZn52/L+3jbtRgCbA/eVv8FoYJ027e7OzKc7aLfETJs2jTvuuIMdd9yR4447jnvvvZdvfvObcx0zYsQIbr311iVdmiRJkpYRtV/62Ikm4OHM3K79jojYdgH7OAv4AzC1Xb8/z8yDO+h34w76uINq9mwb4CvAC8ABwIOZOTNivjno9cxsabftMarZpq2Bie0bZGZzRGxDdR/ZjsDUiPg08A/mDt7Lz2/wYhrwtYjotYCBr72Zbd43s+DXVGftmoDLM/OU93m89803vvENvvGNbwBw3333cfnll3P22Wfz1FNPMWjQIAAmT57Meuutt6RLkyRJ0jKi7jNq9wFblSWJAIeU12nABhGxQ+uBETG0PBjjl8DuEfHBsusI4Lb2HZcZoHMoS+6KW4FPR8Qmbfstb/8JrNKum8nAYcDTmTm7fP5eeQVIoHdrnRGxI7Bc2d6Zp6hm1c6MiP3b74yIvsAamTklM0+lmtUbTHWP3HIR8ZFy6Mh2TXu3bivLC1egCqqTgb8C57QuyYyIPhHxf0q726mWiTaVsQ+gg++zAx19XwviRuDgiFi71NIzIoZ04Xjvm3POOYfhw4czYsQI7r77bk466aRGliNJkqSlWK1n1DLzhYj4MjApIt4AbqJ6cMQzwJ7AWRExhiqEPEF1L9v0iDgBuC0iWsr2L3UyxI+Ar7cZ7/GIOAj4cUSsUPq9m+qBGQ8DGRHTgT+U+9TuA1bn3WA2GTiDaqaNzJxdHoZyXkS0Pkxk37J9Xuf9dETsBPwiIlbIzCvKMsDdqcL1DaW+HlSh9WeZ+VZEfL2c99+Am9t1OwPYojzopAk4sIRLyj1nZwK/L98zVMs+Af6jfE+PlM9XZubPOy3+XZdQhb9vUT1MZIFk5q8i4iRgYkT0pPobXM/cM58dmQx8MyIeAqZ09X1qrYYNG8awYcMAOP/89rdCSpIkSYumqaWl/cq7eomIvpn5anl/GHB4Zn6iwWVpGTB16tRBwJNjJjzHy683L1CbG8/Zq0trkiRJ0rJl1qxZTJ8+HWDdIUOGPLWg7Wo9o1YcHRH7UdX6D6qljJIkSZK0zKp9UMvM06n+32mSJEmS1C3U/WEikiRJktTtGNQkSZIkqWYMapIkSZJUMwY1SZIkSaoZg5okSZIk1YxBTZIkSZJqxqAmSZIkSTVjUJMkSZKkmjGoSZIkSVLNGNQkSZIkqWYMapIkSZJUMwY1SZIkSaoZg5okSZIk1UyvRhcgNdplJ+1Cnz59FujY2XOa6b1czy6uSJIkSd2dM2rSQjCkSZIkaUkwqEmSJElSzRjUJEmSJKlmDGqSJEmSVDMGNUmSJEmqGYOaJEmSJNWMQU2SJEmSasagJkmSJEk1Y1CTJEmSpJoxqEmSJElSzRjUpAU0e05zo0uQJElSN9Gr0QVIjTbq9Nt4+fX5h7Abz9lrCVQjSZIkOaMmSZIkSbVjUJMkSZKkmjGoSZIkSVLNGNQkSZIkqWYMapIkSZJUMwY1SZIkSaoZg5okSZIk1YxBTZIkSZJqxqAmSZIkSTVjUJMkSZKkmjGoSZIkSVLNGNQkSZIkqWYMapIkSZJUMwY1SZIkSaqZXo0uQFqazJo1iy984QvMnj2b5uZmdtttN44++miOOeYYnnzySQBeffVV+vbty4QJExpcrSRJkpZWBrUai4gWoG9mvrYIbb8P/C4z//t9qGMt4OrM3GEexwwCngT+JzP3a7P9CuAQYNPMnD6fcTo934h4ENg2M9+MiKeA4fPrryv07t2bsWPHsuKKKzJnzhxGjhzJdtttx5gxY945ZvTo0ay00kpLujRJkiQtQwxqy6jMPOV97OtZoNOQ1sY/gE0jYtXMfCkiVgI+CTzzPtSwxeL28X5oampixRVXBOCtt97irbfeoqmp6Z39LS0t3HLLLYwdO7ZRJUqSJGkZYFCrkYjYGzgDmAnc0Gb7MGA0sHLZdEpm3hwRlwGPZOZ/leMGAxOB9YGfAA9k5o8ionfp99NAM/BEZn6utPk2sA/VtfAMcERmPt+urkGlr9Uj4gPAWGATYA6Qmfn5cmgL8N/AgcCFwH7A+NJ/a18fAS4G1gDeAv49M3/eZrhvRcRewApl3w2lXYezbRGxJnA+8C+lzbWZecb8vuvF0dzczN57781f/vIXRo4cyeabb/7OvgceeID+/fszaNCgrixBkiRJyzgfJlITETEQuBTYq8wezSq7+gEXASMzcwgwHLg4IvoBV1AtK2x1GHBFZra06/5EYD1gq8zcHDiijHkQVajbJjO3AiYB58yn1N2AlTPzX0tfX2q3fyxwcHl/SKmxrauBazJzM+Ag4KqIWKPN/uZy/nsCl0TEgPnUMw44LzM/CgwBPhMRu8ynzWLp2bMnEyZMYMqUKTz88MM89thj7+y76aabGD58eFcOL0mSpG7AoFYfw4BpmZnl8yXldStgXeCWcp/WLVQzVx/JzF8DfSNi04joRTWT1dGau+HAmMycDZCZfy/b9wR2BqaVvr8GDJpPnQ8BG0fEBRGxH+8GSkrfTwAzI2J3YMXMfKR1X0T0Bbagmu0jMx8FHgS2adPFj8u+BKa12zeXiFgR2B44r9T//4C1gI3ncw7vi5VXXplhw4Zx1113AdVSyNtuu43dd999SQwvSZKkZZhLH+uvCXg4M7frZP9Y4FDgTuD3mfnnhez7tMy8fEEbZOYTEbEJsBPwGeCMiNi0g5rGAd9biFoWRQ+q0Do0M+d08VgA/OMf/6BXr16svPLKzJw5k3vuuYcjjjgCgHvuuYf11luPD37wg0uiFEmSJC3DnFGrj3uBLSNig/J5VHmdBmwQEe88zCMihkZE6xMsxlHNpI2izFR14CbgmHKvGhGxetk+EfhqRKxatveJiM076aN17LWplieOB46lutdstXaHXQ+cTbXM8R2Z+SrVDNohpa+Ngc3Lubc6rOzbANiy3b65lP7uAk5oU986EdFlSenFF1/k4IMPZsSIEey777587GMfY4cdqj/NpEmT2GOPPbpqaEmSJHUjzqjVRGa+GBFHAjdGxJu8+zCRl6iWKJ4VEWOA3sATwAigJTP/EhGPUi0BPLCT7kcDZwIPRsRs4I/Avpl5ZQltUyICquB+IfBQROwJ7JmZo9r1tSkwuhzfEzgzM58tDxxpPZfXypgd+QLVPXbHUj1M5N8y829t9veKiN8CHwC+lJkvdtJP2/7OjYjWJZavAl8Enu+8yaLbaKONGD9+fIf7Ro/u7JQlSZKkhdPU0tL+uRNS9zB16tRBwJNjJjzHy683z/f4G8/Zq8trkiRJ0rJl1qxZTJ8+HWDdIUOGPLWg7Vz6KEmSJEk1Y1CTJEmSpJoxqEmSJElSzRjUJEmSJKlmDGqSJEmSVDMGNUmSJEmqGYOaJEmSJNWMQU2SJEmSasagJkmSJEk1Y1CTJEmSpJoxqEmSJElSzRjUJEmSJKlmDGqSJEmSVDMGNUmSJEmqGYOaJEmSJNVMr0YXIDXaZSftQp8+feZ73Ow5zfRerucSqEiSJEndnTNq0gIypEmSJGlJMahJkiRJUs0Y1CRJkiSpZgxqkiRJklQzBjVJkiRJqhmDmiRJkiTVjEFNkiRJkmrGoCZJkiRJNWNQkyRJkqSaMaip25vzVnOjS5AkSZLmYlBTt7dcr56NLkGSJEmai0FNkiRJkmrGoCZJkiRJNWNQkyRJkqSaMahJkiRJUs0Y1CRJkiSpZgxqkiRJklQzBjVJkiRJqhmDmiRJkiTVjEFNkiRJkmrGoCZJkiRJNWNQkyRJkqSaMahJkiRJUs0Y1CRJkiSpZgxqkiRJklQzvRpdgFQXO+64IyuuuCI9evSgZ8+e/OxnP2t0SZIkSeqmnFGrgYj4bkT0XoDjjomIAQvY550RMXzxq1s8EbF/RNzbwfbvRsRPImKtiPjlfPrYOiKuLu/7RcTxXVXv2LFjmTBhgiFNkiRJDWVQq4dTgfkGNeAYYIGCWo2MBzaIiI1aN0REE3AIcHlmPpuZO8yrg8x8IDO/UD72A7osqEmSJEl14NLHBouIC8rbeyLibWA34CJgfaAJOCszx0XEScBawP9ExExgJLAmcBqwPNXf8vTM/GkHYxwJHAvMogrnn8/MP7Q75rtAAKsA6wF/AvbLzDfKbN/pwKeAPsDDwFdK06eAgZnZHBGPAr/MzK9FxEeBMZn5sYi4BjgM+HZpswMwJzPviohBwAOZuXpEfAAYC2wCzAEyMz8fEdsDZ2fm1sAFQL+IeBB4o/R/KnAgMBNoAXbIzJcX+I/QxmGHHUbPnj3Zf//92X///RelC0mSJGmxOaPWYJn5tfL2Y5m5BXAeMD0zNwN2BUZHxODMPB14Ftg3M7fIzEeBacAnMnNLYGfg7IhYtYNhzgJ2LP0PBf7SSTlbUwXAjYHlgNZZrOOBVzLzo5m5eanjxMx8DfgDMDQi1gTeAD5R2uwETC7vLwf+LSJ6ls+HAT/pYPzdgJUz81/LOF/q4JivAS+X7+BjEbEaVQjdspzfdsBrnZzfPF177bVMmDCBSy+9lKuvvpr7779/UbqRJEmSFptBrX52Bi4GyMzngElUM1AdWYNqhm068AtgNapZsfbuAMZGxFHAhzLzjU76+0VmvpyZLcB9VLN6AHsCB0XEg2Uma882+yaXmncGbgReioi1y+c7ynn8FngB+HRErAzsRTVz1t5DwMYRcUFE7Ec1Azg/rwB/BMZFxBHASpn51gK0e4+BAwcC0L9/f3bZZRcefvjhRelGkiRJWmwGtaXb/wXuBDYts0l/pVoG2d7ewHeAFYFfRsRnOulvZpv3zby7NLYJ+GqZxdoiMzfOzAPKvjuoZs9aZ9AmA8OBLYF72vR3OdVM2v7AXZn5bPvBM/MJqmWPt1EFvYcioqPzadumGdgG+BGwNjA1IjabV5uOvPHGG7z22mvvvL/77rvZYIMNFrYbSZIk6X1hUKuHV6nuDQO4HTgCICI+COxOmZkC/tnmOKgerPFUZrZExC7AR9p3HBG9gPUy8/9l5mjgVqoQtTAmAsdFxAqlz74RsXHZ9xtgc+BjVLNwtwMnAFMzs+2M2NVUSzmPogpt71Fm4pozczzVcsY1qGYJ2/on8IFyXkREX2CNzJySmacC04HBC3l+zJgxg5EjR7Lnnnuy33778alPfYrttttuYbuRJEmS3hc+TKQezgHuiIg3qe7TujgiHqaayTohM39XjjsP+ElEvEF1L9kJwIUR8T3gfqqHfLTXE7giIvoBbwNPl3ZExGXAxMycOJ/6RgPfBe4vDzxpAb4H/D4zZ0fE/cBbmTmnvF+Vd8MlAJn5j4i4BdiRKvh1ZFOqe/Ja6z4zM5+NiA3b9XM18EhEvAR8HrihhMgeVPftLfSz9ddZZx0mTpzf1yBJkiQtGU0tLS2NrkFqiKlTpw4Cnhw8eDB9+vRpdDmSJElaBs2aNYvp06cDrDtkyJCnFrSdSx8lSZIkqWYMapIkSZJUMwY1SZIkSaoZg5okSZIk1YxBTZIkSZJqxqAmSZIkSTVjUJMkSZKkmjGoSZIkSVLNGNQkSZIkqWYMapIkSZJUMwY1SZIkSaoZg5okSZIk1YxBTZIkSZJqxqAmSZIkSTVjUJMkSZKkmjGoqdub81Zzo0uQJEmS5mJQU7e3XK+ejS5BkiRJmotBTZIkSZJqxqAmSZIkSTVjUJMkSZKkmjGoSZIkSVLNGNQkSZIkqWYMapIkSZJUMwY1SZIkSaoZg5okSZIk1YxBTZIkSZJqxqAmSZIkSTVjUJMkSZKkmjGoSZIkSVLNGNQkSZIkqWYMapIkSZJUMwY1SZIkSaoZg5okSZIk1YxBTZIkSZJqxqAmSZIkSTVjUJMkSZKkmjGoSZIkSVLNGNQkSZIkqWYMapIkSZJUMwY1SZIkSaoZg5okSZIk1YxBTZIkSZJqxqAmSZIkSTVjUJMkSZKkmjGoSZIkSVLN9Gp0AVID9QSYPXt2o+uQJEnSMqrNv2v2XJh2BjV1Z2sCPPbYY42uQ5IkScu+NYE/LejBBjV1Z/cDnwSeA5obXIskSZKWTT2pQtr9C9OoqaWlpWvKkSRJkiQtEh8mIkmSJEk1Y1CTJEmSpJoxqEmSJElSzRjUJEmSJKlmDGqSJEmSVDMGNUmSJEmqGYOaJEmSJNWM/8NrdUsRsSEwFugPzAAOzszHG1uV6igingJmln8Avp2Zv5jXNeT1pYg4G9gHGARsmpnTy/ZFum68prqfeVxDT9HBb1LZ5zWkuUREf+BKYH1gNvA48KXM/Ju/R/XnjJq6q4uACzJzQ+AC4OIG16N62zcztyj//KJsm9c15PWl8cB2wJ/bbV/U68Zrqvvp7BqCjn+TwGtI79UC/CAzIzM3Bf4EjC77/D2quaaWlpZG1yAtURExAHgM6J+ZzRHRk+q/CG2QmX9rbHWqm/Jfr4e3/tfssq3Tawho6myf11f30/b6WdTrZl77vKaWfe1/gzr6TSrb/V3SfEXEPsBXgJH4e1R7zqipO1oHeCYzmwHK67Nlu9SRayPikYi4MCL6Me9ryOtLnVnU68ZrSu21/00CryHNR0T0oAppE/H3aKlgUJOkeftkWS6yNdV/SfxRg+uR1L35m6RFdT7wGl4zSw2Dmrqjp4EPlel6yutaZbs0l8x8urzOAi4EPs68ryGvL3VmUa8brym9o5PfJPAa0jyUh9NsAOyfmW/j79FSwaCmbiczXwQeBA4smw4EfuvaarUXEStGxCrlfRNwAPDgvK4hry91ZlGvG68ptersNwkW/fpakvWrMSLiDGAI8NkS8P09Wkr4MBF1SxGxEdWjZVcFXqJ6tGw2tirVTUSsB9wA9Cz/PAocnZnPzesa8vpSRJwH7A18EPg7MCMzN1nU68Zrqvvp6BoCRtDJb1Jp4zWkuUTEJsB0qgeAvFk2P5mZn/P3qP4MapIkSZJUMy59lCRJkqSaMahJkiRJUs0Y1CRJkiSpZgxqkiRJklQzBjVJkiRJqhmDmiRJekdEXBQRJze6Dknq7nw8vyRJ74OIeAoYCDS32bxhZj67GH1uD1yVmWsvVnFLqYi4AvhrZn6n0bVI0pLWq9EFSJK0DBmRmbc3uohWEdErM99qdB2LIiJ6NroGSWokZ9QkSXoflBm1UR0FtYjYBvgh8K/An4GvZ+adZd9hwPHA2sDfgP/MzIsjYkXg70Af4I3S1YbAGbSZZWo/61bq+L/AF4AAVgQGAOcD2wGvAedm5nmdnMcVrf239g2cB3yTarbwK8BsYAywOnB2Zp5R2n4XGFyO2x14HDgsMx8q+zcutW0BPAOcmJkT24z7JvBh4FPAscAFQEsZ75eZOSIiTgCOKOf0NHBSZv5v6eNQYBRwL3A48DLw1cy8pexfDTgH2A1YAZiSmZ8t+4YDpwGDgEeBL2fmwx19R5K0JHiPmiRJXSgiPgTcTBUCVqMKPDdExBrlkBeB4cDKwGHAuRGxVWa+DnwGeDYzVyr/LOgyygOBPYB+wNvAjcBDwIeAnYBjImK3Bezrg8Dype0pwKXAQcAQ4JPAyRGxbpvj9wKuL+d6DTA+IpaLiOVKHbdShayjgKsjItq0HQmcDvQFxgFXAz8o5z6iHPOnMu4qwPeAqyJizTZ9DAOSKkT+APhxRDSVfVcCHwA2KTWcCxARWwKXA18C+gMXAxMjos8CfkeS9L5z6aMkSe+f8RHRutTwzjJbcxAwKTMnle23RcQDVDNOYzPz5jbtp0TErVRBZNpi1HFeZj4NEBHDgDUy8/tl3xMRcSlwAPCLBehrDnB6ZjZHxE+BS4D/ysxXgd9FxKPA5sCT5fipmfk/ZewfAt8Atin7VgJGZ+bbwB0RcRNVqPxu2T8hM+8u72fOneEqmXl9m4//HREnAh8FJpRtf87MS8v4Y4ELgYElrH0G6J+ZL5Vjp5TXI4GLM/O+8nlsRPx7qbv1GElaogxqkiS9fz7bwdLHDwP7RcSINtuWA34JEBGfAU6lWtbYg2rG55HFrOPpduOvFREvt9nWE7hrAfuakZmtD0h5s7y+0Gb/m1QB7D1jZ+bbEfFXYK3WfSWktfoz1UxdR3V3KCIOBo6jWqJIGXv1Noc832b8N0rYW4lqhu8fbUJaWx8GDomIo9ps692mbkla4gxqkiR1raeBKzPziPY7ytK6G4CDqWaT5kTEeKB1qV5HN5K/ThXmWn2wg2PatnsaeDIzN1iU4hfBOq1vIqIH1b13rUs214mIHm3C2r8Aj7Vp2/585/ocER+mWnq5E/CbMsv3IO9+X/PyNLBaRPTLzJc72Hd6Zp6+AP1I0hJhUJMkqWtdBdxf7gm7nWo2bRvgj8ArVA8L+RvwVpld2xWYXtq+APSPiFUy85Wy7UHgGxFx2v9v545ZowqiMAy/2mn+gaUIByWCIBZiY2shwjZpXLEPhDQq+B/sJJXWoo26jU2qBRE0jY3kgIVgIUFBwcoVweIMsgjuRtg1I7xPd4u5M3O7j7nzUac+m3Pmfwl8jYhbVCnIBDgJHMnMVwva47SzETEARsAG8I0q9zhElaLcjIg7wAXgMnBuxrv2gONTzytUePsIv4pYVvezqMz8EBHPgK2IWKdKVc5n5pgKf48jYpv6XkeBi8C4/eIpSf+cZSKSJC1Ruyt2BbhNBYz3wA3gcAsBG8Aj4DNVpjGaGrsLPOHKhCAAAADLSURBVKDulX2JiGNUIcZr4B1VzPFwzvw/qLKSM9Q9sk/APaqMYxmeAmvUfobAIDO/Z+aECmaX2hq2gGttj39yHzjV9v4kM99QrY0vqBB3Gng+Y/zvhtSdu12qxGUTIDN3qCbJu23db4Hrf/FeSVo46/klSdJCtHr+E5l59aDXIkn/O0/UJEmSJKkzBjVJkiRJ6oy/PkqSJElSZzxRkyRJkqTOGNQkSZIkqTMGNUmSJEnqjEFNkiRJkjpjUJMkSZKkzhjUJEmSJKkzPwHhFg91ZmlWTQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7da3657bd550>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = lgb.Dataset(X_train1, label=y_train1)\n",
    "val_data = lgb.Dataset(X_val, label=y_val)\n",
    "params = {\n",
    "            \"objective\" : \"regression\",\n",
    "            \"metric\" : \"rmse\", \n",
    "            \"num_leaves\" : 31,\n",
    "            \"max_depth\" : 7,\n",
    "            \"min_data_in_leaf\": 20,\n",
    "            \"learning_rate\" : 0.07,\n",
    "            \"bagging_fraction\" : 1,\n",
    "            \"feature_fraction\" : 1\n",
    "            }\n",
    "\n",
    "bst = lgb.train(params, train_data, 1000, valid_sets=[val_data], early_stopping_rounds=300, verbose_eval=300)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,18))\n",
    "lgb.plot_importance(bst, max_num_features=30, height=0.8, ax=ax)\n",
    "ax.grid(False)\n",
    "plt.title(\"LightGBM - Feature Importance\", fontsize=15)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
